# US-Monitor çƒ­ç‚¹åˆ†æç³»ç»Ÿ

## TL;DR

> **å¿«é€Ÿæ‘˜è¦**: æ„å»ºä¸€ä¸ªæ™ºèƒ½åˆ†ææµæ°´çº¿ï¼Œä½¿ç”¨ Jaccard ç›¸ä¼¼åº¦å¯¹çˆ¬å–çš„ RSS æ–°é—»æ–‡ç« ï¼ˆ199 ä¸ªæ¥æºï¼‰è¿›è¡Œèšç±»ï¼ŒæŒ‰é¢†åŸŸåˆ†ç±»ï¼ˆæ”¿æ²»/åœ°ç¼˜æ”¿æ²»ã€ç»æµã€å†›äº‹ï¼‰ï¼Œå¹¶ä½¿ç”¨é˜¿é‡Œå·´å·´ Qwen3-Plus å¤§æ¨¡å‹ç”Ÿæˆçƒ­ç‚¹åˆ†æï¼ŒåŒ…å«è¶‹åŠ¿æ£€æµ‹å’Œå‡çº§è¯„åˆ†ã€‚ä½œä¸ºç‹¬ç«‹çš„ GitHub Actions å·¥ä½œæµï¼Œåœ¨çˆ¬è™«å®Œæˆåè¿è¡Œã€‚
>
> **äº¤ä»˜ç‰©**:
> 
> **æ ¸å¿ƒåˆ†æ (Core Analysis)**:
> - æ•°æ®åº“è¡¨ç»“æ„: `analysis_clusters`, `analysis_signals` è¡¨
> - Python åˆ†ææµæ°´çº¿: `scripts/analyzer.py` (ä¸­æ–‡è¾“å‡º)
> - LLM é›†æˆ: é˜¿é‡Œå·´å·´ Qwen3-Plus API å®¢æˆ·ç«¯ (ä¸­æ–‡æç¤ºè¯)
> - èšç±»å¼•æ“: å¸¦å€’æ’ç´¢å¼•çš„ Jaccard ç›¸ä¼¼åº¦
> - ä¿¡å·æ£€æµ‹: velocity_spike, convergence, triangulation, hotspot_escalation
> - GitHub Actions å·¥ä½œæµ: `.github/workflows/analyzer.yml`
> 
> **å…è´¹æ•°æ®æº (Free Data Sources)**:
> - FRED å®¢æˆ·ç«¯: ç¾å›½ç»æµæ•°æ® (å…è´¹, éœ€ API key)
> - GDELT å®¢æˆ·ç«¯: å…¨çƒäº‹ä»¶æ•°æ®åº“ (å®Œå…¨å…è´¹)
> - USGS å®¢æˆ·ç«¯: åœ°éœ‡æ•°æ® (å®Œå…¨å…è´¹)
> - World Bank å®¢æˆ·ç«¯: ç»æµæŒ‡æ ‡ (å®Œå…¨å…è´¹)
> - å¢å¼ºä¿¡å·: æ•°æ®æºèåˆå¢å¼ºä¿¡å·
> 
> **UI ä»ªè¡¨æ¿ (Web Dashboard)**:
> - Streamlit Webåº”ç”¨: ä¸­æ–‡ç•Œé¢
> - é¡µé¢: æ¦‚è§ˆé¦–é¡µã€çƒ­ç‚¹è¯¦æƒ…ã€ä¿¡å·ä¸­å¿ƒã€æ•°æ®ç»Ÿè®¡
> - ç§»åŠ¨ç«¯å“åº”å¼æ”¯æŒ
> - ä¸€é”®éƒ¨ç½²æ–‡æ¡£
>
> **é¢„ä¼°å·¥ä½œé‡**: å¤§å‹é¡¹ç›® (10-12 å°æ—¶)  
> **å¹¶è¡Œæ‰§è¡Œ**: å¯ä»¥ - 6 æ³¢æ¬¡ (åŸºç¡€ â†’ æ ¸å¿ƒ â†’ é›†æˆ â†’ éªŒè¯ â†’ å¢å¼º â†’ æœ€ç»ˆ)  
> **å…³é”®è·¯å¾„**: æ•°æ®åº“è¡¨ç»“æ„ â†’ èšç±» â†’ åˆ†æå™¨ â†’ å¢å¼ºåˆ†æå™¨ â†’ æœ€ç»ˆæµ‹è¯•  
> **æ–°å¢åŠŸèƒ½**: ä¸­æ–‡è¾“å‡ºã€Web UIä»ªè¡¨æ¿ã€4ä¸ªå…è´¹æ•°æ®æºé›†æˆ

---

## èƒŒæ™¯

### åŸå§‹éœ€æ±‚
"å¸®æˆ‘å­¦ä¹ worldmonitorï¼Œè®¾è®¡ä¸€ä¸ªåŸºäºç°åœ¨çˆ¬å–æ•°æ®çš„çƒ­ç‚¹åˆ†æåŠŸèƒ½ï¼Œå¯ä»¥åˆ†ä¸ºæ”¿æ²»/åœ°ç¼˜ ç»æµ å†›äº‹ä¸‰ä¸ªåˆ†ç±»ã€‚æ€»ç»“åˆ†æä½¿ç”¨é˜¿é‡Œqwen3-plusçš„åœ¨çº¿å¤§æ¨¡å‹ã€‚"

(å€Ÿé‰´ worldmonitorï¼ŒåŸºäºå½“å‰çˆ¬å–çš„æ•°æ®è®¾è®¡çƒ­ç‚¹åˆ†æåŠŸèƒ½ï¼Œåˆ†ä¸ºæ”¿æ²»/åœ°ç¼˜æ”¿æ²»ã€ç»æµã€å†›äº‹ä¸‰ä¸ªåˆ†ç±»ã€‚ä½¿ç”¨é˜¿é‡Œå·´å·´ Qwen3-Plus å¤§æ¨¡å‹è¿›è¡Œæ€»ç»“å’Œåˆ†æã€‚)

### è®¿è°ˆæ‘˜è¦

**å…³é”®è®¨è®º**:
- ä¿®å¤äº†çˆ¬è™« bugï¼ˆæ—¶é—´æˆ³æ ¼å¼ã€Twitter/X header æº¢å‡ºï¼‰
- RSS æºä» 172 æ‰©å±•åˆ° 199ï¼ˆæ·»åŠ äº† worldmonitor é«˜çº§æºï¼‰
- å½“å‰æ•°æ®åº“: 1000+ å”¯ä¸€æ–‡ç« ï¼ŒSimHash å»é‡æ­£å¸¸å·¥ä½œ
- è°ƒåº¦: GitHub Actions æ¯å¤©ä¸Šåˆ 9 ç‚¹å’Œæ™šä¸Š 9 ç‚¹ï¼ˆç¾ä¸œæ—¶é—´ï¼‰è¿è¡Œä¸¤æ¬¡
- å†…å®¹æå–çš„ Cloudflare Worker å·²éƒ¨ç½²

**ç”¨æˆ·æ„å›¾**: åœ¨ç°æœ‰çˆ¬è™«åŸºç¡€è®¾æ–½ä¹‹ä¸Šæ„å»ºæ™ºèƒ½åˆ†æå±‚ï¼Œå€Ÿé‰´ worldmonitor çš„æ¶æ„ï¼Œä½†é’ˆå¯¹ç¾å›½æ–°é—»ç›‘æ§è¿›è¡Œè°ƒæ•´ã€‚

### ç ”ç©¶å‘ç°

**å·²åˆ†æçš„ WorldMonitor æ¶æ„**:
- **analysis-core.ts**: Jaccard ç›¸ä¼¼åº¦èšç±» (SIMILARITY_THRESHOLD=0.5)ï¼Œå»é™¤åœç”¨è¯çš„åˆ†è¯ï¼Œç”¨äºé«˜æ•ˆåŒ¹é…çš„å€’æ’ç´¢å¼•
- **hotspot-escalation.ts**: å¸¦åŠ æƒç»„ä»¶çš„åŠ¨æ€å‡çº§è¯„åˆ†ï¼ˆæ–°é—» 35%ï¼ŒCII 25%ï¼Œåœ°ç† 25%ï¼Œå†›äº‹ 15%ï¼‰ï¼Œä¿¡å·å†·å´æœŸï¼ˆ2 å°æ—¶ï¼‰ï¼Œå†å²è¶‹åŠ¿è·Ÿè¸ª
- **analysis.worker.ts**: ç”¨äº O(nÂ²) èšç±»çš„ Web Workerï¼Œç‹¬ç«‹äºä¸»çº¿ç¨‹ï¼ŒçŠ¶æ€åœ¨åˆ†æä¹‹é—´æŒä¹…åŒ–ï¼Œä¿¡å·å»é‡
- **analysis-constants.ts**: å¸¦ä¸Šä¸‹æ–‡è§£é‡Šçš„ä¿¡å·ç±»å‹ï¼ˆwhyItMatters, actionableInsight, confidenceNoteï¼‰ï¼Œä¸»é¢˜å…³é”®è¯æ˜ å°„

**é‡‡ç”¨çš„å…³é”®æ¨¡å¼**:
1. æ ¸å¿ƒåˆ†æä½¿ç”¨çº¯å‡½æ•°ï¼ˆæ— å‰¯ä½œç”¨ï¼‰
2. èšç±»: åˆ†è¯ â†’ Jaccard ç›¸ä¼¼åº¦ â†’ å€’æ’ç´¢å¼•ä¼˜åŒ–
3. ä¿¡å·: velocity_spike, convergence, triangulation, hotspot_escalation
4. é€šè¿‡ generateDedupeKey è¿›è¡Œä¿¡å·å»é‡
5. å‡çº§è¯„åˆ†åŠ æƒï¼ˆæ–°é—»é€Ÿåº¦ã€æ¥æºå¤šæ ·æ€§ã€åœ°ç†æ±‡èšï¼‰

### Metis è¯„å®¡

**å·²è¯†åˆ«çš„å·®è·**ï¼ˆæœ¬è®¡åˆ’ä¸­å·²è§£å†³ï¼‰:
1. è¾“å‡ºæ ¼å¼å·²å®šä¹‰: ç»“æ„åŒ– JSONï¼ŒåŒ…å«æ‘˜è¦ã€ä¿¡å·ã€å‡çº§è¯„åˆ†
2. æ—¶é—´çª—å£: æœ€è¿‘ 24 å°æ—¶çš„æœªåˆ†ææ–‡ç« 
3. å¢é‡å¤„ç†: åªåˆ†æ `analyzed_at IS NULL` çš„æ–‡ç« 
4. LLM ç­–ç•¥: æŒ‰èšç±»æ€»ç»“ï¼ˆä¸æ˜¯æŒ‰æ–‡ç« ï¼Œä»¥æ§åˆ¶æˆæœ¬ï¼‰
5. èŒƒå›´é”å®š: æ—  UI/ä»ªè¡¨æ¿ï¼Œæ— å®æ—¶å¤„ç†ï¼Œæ— è‡ªå®šä¹‰ ML
6. çƒ­ç‚¹å®šä¹‰: åŸºäºä¸»é¢˜/ä¸»é¢˜çš„èšç±»ï¼ˆä¸åƒ worldmonitor é‚£æ ·åŸºäºåœ°ç†ï¼‰
7. è¯­è¨€: è‹±æ–‡è¾“å‡ºï¼ˆæ¥æºåŸºäºç¾å›½ï¼‰
8. åˆ†æå·¥ä½œæµ: ä¸çˆ¬è™«åˆ†ç¦»ï¼Œåœ¨çˆ¬è™«å®Œæˆåè§¦å‘

**åº”ç”¨çš„é˜²æŠ¤æªæ–½**:
- æ¯æ¬¡è¿è¡Œæœ€å¤š 500 ç¯‡æ–‡ç« ï¼ˆGitHub Actions æ—¶é—´é™åˆ¶ï¼‰
- æ¯æ¬¡è¿è¡Œæœ€å¤š 200 æ¬¡ LLM API è°ƒç”¨ï¼ˆæˆæœ¬æ§åˆ¶ï¼‰
- API è°ƒç”¨å‰è¿›è¡Œ Token ä¼°ç®—
- å¸¦æŒ‡æ•°é€€é¿çš„é‡è¯•é€»è¾‘ï¼ˆ3 æ¬¡å°è¯•ï¼‰
- å°†é•¿å†…å®¹æˆªæ–­è‡³ 4000 å­—ç¬¦
- è·³è¿‡å†…å®¹ <100 å­—ç¬¦ã€æ ‡é¢˜ <10 å­—ç¬¦çš„æ–‡ç« 
- åˆ†æç»“æœä¿ç•™ 90 å¤©

---

## å·¥ä½œç›®æ ‡

### æ ¸å¿ƒç›®æ ‡
å®ç°ä¸€ä¸ªæ™ºèƒ½æ–°é—»åˆ†ææµæ°´çº¿ï¼Œä½¿ç”¨ LLM é©±åŠ¨çš„æ€»ç»“å’Œå— worldmonitor å¯å‘çš„èšç±»åŠä¿¡å·æ£€æµ‹ç®—æ³•ï¼Œå°†åŸå§‹çˆ¬å–çš„ RSS æ–‡ç« è½¬åŒ–ä¸ºå¯æ“ä½œçš„çƒ­ç‚¹æƒ…æŠ¥ã€‚

### å…·ä½“äº¤ä»˜ç‰©
#### æ ¸å¿ƒåˆ†æ
- `sql/analysis_schema.sql` - åˆ†æç»“æœçš„æ•°æ®åº“è¡¨
- `scripts/analyzer.py` - ä¸»åˆ†ææµæ°´çº¿
- `scripts/clustering.py` - Jaccard ç›¸ä¼¼åº¦èšç±»å¼•æ“
- `scripts/llm_client.py` - é˜¿é‡Œå·´å·´ Qwen3-Plus API å®¢æˆ·ç«¯ (ä¸­æ–‡è¾“å‡º)
- `scripts/signal_detector.py` - ä¿¡å·æ£€æµ‹ç®—æ³•
- `.github/workflows/analyzer.yml` - GitHub Actions å·¥ä½œæµ
- `.env.example` - æ›´æ–°åˆ†æé…ç½®
- `config/analysis_config.py` - é˜ˆå€¼ã€æç¤ºè¯ (ä¸­æ–‡)ã€å¸¸é‡

#### æ•°æ®æº (å…è´¹/ä½æˆæœ¬)
- `scripts/datasources/fred_client.py` - FRED ç¾å›½ç»æµæ•°æ® (å…è´¹ï¼Œéœ€ API key)
- `scripts/datasources/gdelt_client.py` - GDELT å…¨çƒäº‹ä»¶æ•°æ®åº“ (å…è´¹)
- `scripts/datasources/earthquake_client.py` - USGS åœ°éœ‡æ•°æ® (å…è´¹)
- `scripts/datasources/worldbank_client.py` - ä¸–ç•Œé“¶è¡ŒæŒ‡æ ‡ (å…è´¹)
- `scripts/datasources/enhanced_signals.py` - å¢å¼ºä¿¡å·æ£€æµ‹ï¼ˆç»“åˆå¤šæ•°æ®æºï¼‰

#### UI ä»ªè¡¨æ¿
- `web/app.py` - Flask/Streamlit Web åº”ç”¨ä¸»å…¥å£
- `web/templates/index.html` - ä¸»ä»ªè¡¨æ¿é¡µé¢ï¼ˆä¸­æ–‡ç•Œé¢ï¼‰
- `web/templates/hotspots.html` - çƒ­ç‚¹è¯¦æƒ…é¡µ
- `web/templates/signals.html` - ä¿¡å·åˆ—è¡¨é¡µ
- `web/static/css/style.css` - æ ·å¼è¡¨
- `web/static/js/dashboard.js` - å‰ç«¯äº¤äº’
- `web/data_api.py` - æ•°æ®æŸ¥è¯¢ API
- `web/README.md` - UI éƒ¨ç½²è¯´æ˜

### å®Œæˆå®šä¹‰
- [ ] åˆ†ææµæ°´çº¿åœ¨ 30 åˆ†é’Ÿå†…å®Œæˆ 500 ç¯‡æ–‡ç« 
- [ ] æˆåŠŸè°ƒç”¨é˜¿é‡Œå·´å·´ Qwen3-Plus API å¹¶å­˜å‚¨ç»“æ„åŒ– JSON ç»“æœ
- [ ] å°† 1000 ç¯‡æ–‡ç« èšç±»ä¸º 50-200 ä¸ªæœ‰æ„ä¹‰çš„èšç±»ï¼ˆé€šè¿‡æ•°æ®åº“æŸ¥è¯¢éªŒè¯ï¼‰
- [ ] å½“å­˜åœ¨é‡å¤§æ–°é—»æ—¶ï¼Œæ¯æ¬¡è¿è¡Œè‡³å°‘æ£€æµ‹åˆ° 1 ä¸ªä¿¡å·
- [ ] åªå¤„ç†æœªåˆ†æçš„æ–‡ç« ï¼ˆå·²éªŒè¯å¢é‡å¤„ç†ï¼‰
- [ ] æ‰€æœ‰éªŒæ”¶æ ‡å‡†é€šè¿‡ä»£ç†æ‰§è¡Œçš„ QA åœºæ™¯

### å¿…é¡»æœ‰
- èšç±»å’Œä¿¡å·çš„æ•°æ®åº“è¡¨ç»“æ„
- å¸¦å€’æ’ç´¢å¼•çš„ Jaccard ç›¸ä¼¼åº¦èšç±»
- é˜¿é‡Œå·´å·´ Qwen3-Plus LLM é›†æˆ
- æŒ‰èšç±»æ€»ç»“
- ä¿¡å·æ£€æµ‹: velocity_spike, convergence
- å¢é‡å¤„ç†ï¼ˆä»…æ–°æ–‡ç« ï¼‰
- ä¼˜é›…é™çº§çš„é”™è¯¯å¤„ç†
- GitHub Actions å·¥ä½œæµ

### ç¦æ­¢æœ‰ (é˜²æŠ¤æªæ–½)
- **æ— å®æ—¶å¤„ç†** - ä»…æ‰¹å¤„ç†ï¼Œé€šè¿‡ GitHub Actions è°ƒåº¦
- **æ— è‡ªå®šä¹‰ ML æ¨¡å‹** - ä»…ä½¿ç”¨ Qwen3-Plusï¼Œä¸è®­ç»ƒæ¨¡å‹
- **æ— å¸‚åœºæ•°æ®é›†æˆ** - è·³è¿‡ prediction_leads_news, news_leads_markets ä¿¡å·ï¼ˆæ— å¸‚åœºæ•°æ®æºï¼‰
- **åˆæœŸæ— é«˜çº§ä¿¡å·** - ä»…å¼€å§‹æ—¶ä½¿ç”¨ 4 ä¸ªæ ¸å¿ƒä¿¡å·

### ä¸åŸå§‹è®¡åˆ’çš„å…³é”®å˜åŒ–
1. **ä¸­æ–‡è¾“å‡º** - æ‰€æœ‰åˆ†ææ‘˜è¦ç”¨ä¸­æ–‡è¾“å‡ºï¼Œä½†ä¿ç•™è‹±æ–‡åŸæ–‡é“¾æ¥ä¾›æº¯æº
2. **UIå±•ç¤º** - æ·»åŠ  Web ä»ªè¡¨æ¿ï¼Œå±•ç¤ºçƒ­ç‚¹åˆ†æç»“æœï¼ˆPython Flask/Streamlitï¼‰
3. **å…è´¹æ•°æ®æºå¢å¼º** - é›†æˆ worldmonitor ä¸­å¯ç”¨çš„å…è´¹/ä½æˆæœ¬æ•°æ®æº

---

## éªŒè¯ç­–ç•¥

> **é€šç”¨è§„åˆ™: é›¶äººå·¥å¹²é¢„**
>
> æ‰€æœ‰ä»»åŠ¡å¿…é¡»å¯ç”±ä»£ç†ä½¿ç”¨å·¥å…·éªŒè¯ã€‚æ— éœ€äººå·¥æµ‹è¯•ã€‚

### æµ‹è¯•å†³ç­–
- **åŸºç¡€è®¾æ–½å­˜åœ¨**: æ˜¯ - Supabase PostgreSQL å·²é…ç½®
- **è‡ªåŠ¨åŒ–æµ‹è¯•**: æµ‹è¯•åç½®ï¼ˆæ ¸å¿ƒå®ç°åæ·»åŠ å•å…ƒæµ‹è¯•ï¼‰
- **æ¡†æ¶**: Python unittestï¼ˆä¸ç°æœ‰è„šæœ¬ä¿æŒä¸€è‡´ï¼‰

### ä»£ç†æ‰§è¡Œçš„ QA åœºæ™¯ (å¼ºåˆ¶)

æ¯ä¸ªä»»åŠ¡åŒ…å«å…·ä½“åœºæ™¯ï¼ŒåŒ…å«ç¡®åˆ‡çš„å‘½ä»¤ã€æ–­è¨€å’Œè¯æ®è·¯å¾„ã€‚

**æŒ‰ç±»å‹åˆ†ç±»çš„éªŒè¯å·¥å…·:**
| ç±»å‹ | å·¥å…· | ä»£ç†å¦‚ä½•éªŒè¯ |
|------|------|-------------|
| **æ•°æ®åº“** | Bash (psql) | æŸ¥è¯¢è¡¨ï¼Œæ–­è¨€è¡Œæ•°ï¼ŒéªŒè¯è¡¨ç»“æ„ |
| **Python** | Bash (python) | è¿è¡Œè„šæœ¬ï¼Œæ£€æŸ¥é€€å‡ºä»£ç ï¼ŒéªŒè¯è¾“å‡º |
| **API** | Bash (curl) | å‘é€è¯·æ±‚ï¼Œè§£æ JSONï¼Œæ–­è¨€çŠ¶æ€ç  |
| **GitHub Actions** | Web | æ£€æŸ¥å·¥ä½œæµè¿è¡Œï¼ŒæŸ¥çœ‹æ—¥å¿— |

---

## æ‰§è¡Œç­–ç•¥

### å¹¶è¡Œæ‰§è¡Œæ³¢æ¬¡

```
æ³¢æ¬¡ 1 (åŸºç¡€ - å¯ç«‹å³å¼€å§‹):
â”œâ”€â”€ ä»»åŠ¡ 1: æ•°æ®åº“è¡¨ç»“æ„ (æ— ä¾èµ–)
â”œâ”€â”€ ä»»åŠ¡ 2: LLM å®¢æˆ·ç«¯æ¨¡å— (æ— ä¾èµ–)
â””â”€â”€ ä»»åŠ¡ 3: é…ç½®ä¸å¸¸é‡ (æ— ä¾èµ–)

æ³¢æ¬¡ 2 (æ ¸å¿ƒé€»è¾‘ - æ³¢æ¬¡ 1 ä¹‹å):
â”œâ”€â”€ ä»»åŠ¡ 4: èšç±»å¼•æ“ (ä¾èµ–: ä»»åŠ¡ 3)
â””â”€â”€ ä»»åŠ¡ 5: ä¿¡å·æ£€æµ‹ (ä¾èµ–: ä»»åŠ¡ 3)

æ³¢æ¬¡ 3 (é›†æˆ - æ³¢æ¬¡ 2 ä¹‹å):
â”œâ”€â”€ ä»»åŠ¡ 6: ä¸»åˆ†æå™¨æµæ°´çº¿ (ä¾èµ–: 1, 2, 4, 5)
â””â”€â”€ ä»»åŠ¡ 7: GitHub Actions å·¥ä½œæµ (ä¾èµ–: 6)

æ³¢æ¬¡ 4 (éªŒè¯ - æ³¢æ¬¡ 3 ä¹‹å):
â””â”€â”€ ä»»åŠ¡ 8: ç«¯åˆ°ç«¯æµ‹è¯• (ä¾èµ–: 7)

å…³é”®è·¯å¾„: ä»»åŠ¡ 1 â†’ ä»»åŠ¡ 4 â†’ ä»»åŠ¡ 6 â†’ ä»»åŠ¡ 7 â†’ ä»»åŠ¡ 8
å¹¶è¡ŒåŠ é€Ÿ: æ¯”é¡ºåºæ‰§è¡Œå¿«çº¦ 30%
```

### ä¾èµ–çŸ©é˜µ

| ä»»åŠ¡ | ä¾èµ–äº | é˜»å¡ | å¯ä¸ä»¥ä¸‹å¹¶è¡Œ |
|------|--------|------|-------------|
| 1 | æ—  | 6 | 2, 3 |
| 2 | æ—  | 6 | 1, 3 |
| 3 | æ—  | 4, 5 | 1, 2 |
| 4 | 3 | 6 | 5 |
| 5 | 3 | 6 | 4 |
| 6 | 1, 2, 4, 5 | 7 | æ—  |
| 7 | 6 | 8 | æ—  |
| 8 | 7 | æ—  | æ—  |

---

## ä»»åŠ¡æ¸…å•

### ä»»åŠ¡ 1: æ•°æ®åº“è¡¨ç»“æ„

**åšä»€ä¹ˆ**:
ä¸ºåˆ†æç»“æœå­˜å‚¨åˆ›å»º SQL è¡¨ç»“æ„:
1. `analysis_clusters` è¡¨ - å­˜å‚¨èšç±»ä¿¡æ¯
2. `analysis_signals` è¡¨ - å­˜å‚¨æ£€æµ‹åˆ°çš„ä¿¡å·
3. `article_analyses` è¿æ¥è¡¨ - å°†æ–‡ç« é“¾æ¥åˆ°èšç±»
4. ä¸ºç°æœ‰çš„ `articles` è¡¨æ·»åŠ  `analyzed_at` åˆ—
5. åˆ›å»ºæ€§èƒ½ç´¢å¼•

**ç¦æ­¢åš**:
- é™¤äº†æ·»åŠ  `analyzed_at` å¤–ï¼Œä¸è¦ä¿®æ”¹ç°æœ‰ `articles` è¡¨ç»“æ„
- ä¸è¦åˆ é™¤ç°æœ‰è¡¨
- ä¸è¦åˆ›å»ºä¼šé˜»æ­¢åˆ é™¤çš„å¤–é”®çº¦æŸ

**æ¨èä»£ç†é…ç½®**:
- **åˆ†ç±»**: unspecified-low
- **åŸå› **: SQL è¡¨ç»“æ„åˆ›å»ºç®€å•ç›´æ¥ï¼Œå¤æ‚åº¦ä½
- **æŠ€èƒ½**: ä¸éœ€è¦

**å¹¶è¡ŒåŒ–**:
- **å¯å¹¶è¡Œè¿è¡Œ**: æ˜¯ - æ³¢æ¬¡ 1
- **é˜»å¡**: ä»»åŠ¡ 6 (ä¸»åˆ†æå™¨)
- **è¢«é˜»å¡äº**: æ— 

**å‚è€ƒ**:
- æ¨¡å¼: éµå¾ª `sql/schema.sql` ä¸­çš„ç°æœ‰è¡¨ç»“æ„
- ç›¸ä¼¼è¡¨: `articles` è¡¨ç»“æ„ç”¨äºåˆ—ç±»å‹
- WorldMonitor: `analysis-core.ts:ClusteredEventCore` æ¥å£ç”¨äºæ•°æ®ç»“æ„

**éªŒæ”¶æ ‡å‡†**:

**ä»£ç†æ‰§è¡Œçš„ QA åœºæ™¯:**

```
åœºæ™¯: è¡¨ç»“æ„åˆ›å»ºæˆåŠŸ
  å·¥å…·: Bash (psql)
  å‰ç½®æ¡ä»¶: ç¯å¢ƒä¸­é…ç½® Supabase å‡­è¯
  æ­¥éª¤:
    1. è¿è¡Œ: psql $SUPABASE_URL -f sql/analysis_schema.sql
    2. æ–­è¨€: é€€å‡ºä»£ç  0
    3. æŸ¥è¯¢: \dt analysis_*
    4. æ–­è¨€: æ˜¾ç¤º analysis_clusters, analysis_signals, article_analyses

åœºæ™¯: è¡¨å…·æœ‰æ­£ç¡®çš„ç»“æ„
  å·¥å…·: Bash (psql)
  æ­¥éª¤:
    1. æŸ¥è¯¢: SELECT column_name, data_type FROM information_schema.columns WHERE table_name = 'analysis_clusters'
    2. æ–­è¨€: åˆ—åŒ…å« id, cluster_key, category, primary_title, summary, article_count, created_at, updated_at
    3. æŸ¥è¯¢: SELECT column_name FROM information_schema.columns WHERE table_name = 'articles' AND column_name = 'analyzed_at'
    4. æ–­è¨€: analyzed_at åˆ—å­˜åœ¨
    5. è¯æ®: æŸ¥è¯¢ç»“æœæˆªå›¾

åœºæ™¯: ä¸ºæ€§èƒ½åˆ›å»ºç´¢å¼•
  å·¥å…·: Bash (psql)
  æ­¥éª¤:
    1. æŸ¥è¯¢: SELECT indexname FROM pg_indexes WHERE tablename = 'analysis_clusters'
    2. æ–­è¨€: cluster_key ä¸Šå­˜åœ¨ç´¢å¼•
    3. æ–­è¨€: created_at ä¸Šå­˜åœ¨ç´¢å¼•
    4. è¯æ®: ä¿å­˜æŸ¥è¯¢è¾“å‡º
```

**æäº¤**: æ˜¯
- æ¶ˆæ¯: `feat(db): add analysis schema for hotspot detection`
- æ–‡ä»¶: `sql/analysis_schema.sql`
- æäº¤å‰: éªŒè¯è¡¨ç»“æ„æ— é”™è¯¯åº”ç”¨

---

### ä»»åŠ¡ 2: LLM å®¢æˆ·ç«¯æ¨¡å—

**åšä»€ä¹ˆ**:
ä¸ºé˜¿é‡Œå·´å·´ Qwen3-Plus API é›†æˆåˆ›å»º Python æ¨¡å—:
1. `scripts/llm_client.py` - API å®¢æˆ·ç«¯ç±»
2. ä½¿ç”¨ API key å®ç°è®¤è¯
3. ä½¿ç”¨ JSON æ¨¡å¼è¿›è¡Œè¯·æ±‚/å“åº”å¤„ç†
4. Token ä¼°ç®—å’Œæˆæœ¬è·Ÿè¸ª
5. å¸¦æŒ‡æ•°é€€é¿çš„é‡è¯•é€»è¾‘ï¼ˆ3 æ¬¡å°è¯•ï¼‰
6. å“åº”ç¼“å­˜ä»¥é¿å…é‡å¤è°ƒç”¨
7. é€Ÿç‡é™åˆ¶ã€è¶…æ—¶ã€æ ¼å¼é”™è¯¯å“åº”çš„é”™è¯¯å¤„ç†

**ç¦æ­¢åš**:
- ä¸è¦å®ç°æµå¼å“åº”ï¼ˆä¸éœ€è¦ï¼‰
- ä¸è¦åˆæœŸæ”¯æŒå¤šä¸ª LLM æä¾›å•†
- ä¸è¦å®ç°å¾®è°ƒæˆ–è‡ªå®šä¹‰æ¨¡å‹

**æ¨èä»£ç†é…ç½®**:
- **åˆ†ç±»**: unspecified-high
- **åŸå› **: API é›†æˆéœ€è¦å¥å£®çš„é”™è¯¯å¤„ç†ã€é‡è¯•é€»è¾‘ã€å¼‚æ­¥æ¨¡å¼
- **æŠ€èƒ½**: ä¸éœ€è¦ï¼ˆçº¯ Pythonï¼‰

**å¹¶è¡ŒåŒ–**:
- **å¯å¹¶è¡Œè¿è¡Œ**: æ˜¯ - æ³¢æ¬¡ 1
- **é˜»å¡**: ä»»åŠ¡ 6 (ä¸»åˆ†æå™¨)
- **è¢«é˜»å¡äº**: æ— 

**å‚è€ƒ**:
- WorldMonitor: `api/groq-summarize.js` ç”¨äº API è°ƒç”¨æ¨¡å¼å’Œç¼“å­˜ç­–ç•¥
- ç°æœ‰ä»£ç : `scripts/crawler.py` ç”¨äº Supabase å®¢æˆ·ç«¯æ¨¡å¼
- å¤–éƒ¨: é˜¿é‡Œå·´å·´ DashScope API æ–‡æ¡£ (https://help.aliyun.com/zh/dashscope/)

**éªŒæ”¶æ ‡å‡†**:

**ä»£ç†æ‰§è¡Œçš„ QA åœºæ™¯:**

```
åœºæ™¯: LLM å®¢æˆ·ç«¯ç”¨ API key åˆå§‹åŒ–
  å·¥å…·: Bash (python)
  å‰ç½®æ¡ä»¶: ç¯å¢ƒä¸­è®¾ç½® ALIBABA_API_KEY
  æ­¥éª¤:
    1. è¿è¡Œ: python -c "from scripts.llm_client import LLMClient; c = LLMClient(); print('Initialized')"
    2. æ–­è¨€: è¾“å‡ºåŒ…å« "Initialized"
    3. æ–­è¨€: é€€å‡ºä»£ç  0

åœºæ™¯: API è°ƒç”¨è¿”å›ç»“æ„åŒ– JSON
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. åˆ›å»ºæµ‹è¯•è„šæœ¬: test_llm.py (ä»»åŠ¡ä¸­æä¾›)
    2. è¿è¡Œ: python test_llm.py
    3. æ–­è¨€: å“åº”æ˜¯æœ‰æ•ˆçš„ JSON
    4. æ–­è¨€: å“åº”åŒ…å«é¢„æœŸå­—æ®µ (summary, keywords, sentiment)
    5. è¯æ®: ä¿å­˜å“åº”åˆ° .sisyphus/evidence/task-2-llm-response.json

åœºæ™¯: å¤±è´¥æ—¶é‡è¯•æœ‰æ•ˆ
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. ä¸´æ—¶é…ç½®æ— æ•ˆçš„ API key
    2. è¿è¡Œ: python -c "from scripts.llm_client import LLMClient; c = LLMClient(); c.summarize('test')" 2>&1
    3. æ–­è¨€: æ—¥å¿—æ˜¾ç¤º 3 æ¬¡é‡è¯•å°è¯•
    4. æ–­è¨€: æœ€ç»ˆé”™è¯¯æ˜¯ä¼˜é›…çš„ï¼ˆä¸å´©æºƒï¼‰
    5. è¯æ®: é‡è¯•æ—¥å¿—æˆªå›¾

åœºæ™¯: ç¼“å­˜é˜²æ­¢é‡å¤è°ƒç”¨
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. ç”¨ç›¸åŒè¾“å…¥è°ƒç”¨ LLM ä¸¤æ¬¡
    2. æ–­è¨€: ç¬¬äºŒæ¬¡è°ƒç”¨è¿”å›ç¼“å­˜ç»“æœï¼ˆæ›´å¿«ï¼Œæ—  API æ—¥å¿—ï¼‰
    3. è¯æ®: æ¯”è¾ƒæ—¥å¿—ä¸­çš„æ—¶é—´æˆ³
```

**æäº¤**: æ˜¯
- æ¶ˆæ¯: `feat(llm): add Alibaba Qwen3-Plus client with retry and caching`
- æ–‡ä»¶: `scripts/llm_client.py`, `.env.example` (å·²æ›´æ–°)
- æäº¤å‰: éªŒè¯å®¢æˆ·ç«¯å¯¼å…¥æ— é”™è¯¯

---

### ä»»åŠ¡ 3: é…ç½®ä¸å¸¸é‡

**åšä»€ä¹ˆ**:
åˆ›å»ºé›†ä¸­å¼é…ç½®æ¨¡å—:
1. `config/analysis_config.py` - æ‰€æœ‰é˜ˆå€¼å’Œå¸¸é‡
2. å®šä¹‰ Jaccard ç›¸ä¼¼åº¦é˜ˆå€¼ï¼ˆé»˜è®¤: 0.5ï¼‰
3. å®šä¹‰åˆ†è¯çš„åœç”¨è¯
4. ä¸ºæ¯ä¸ªåˆ†ç±»å®šä¹‰ä¸»é¢˜å…³é”®è¯ï¼ˆå†›äº‹ã€æ”¿æ²»ã€ç»æµï¼‰
5. å®šä¹‰ä¿¡å·æ£€æµ‹é˜ˆå€¼
6. å®šä¹‰ LLM æç¤ºè¯ï¼ˆèšç±»æ€»ç»“ã€ä¿¡å·æ¨ç†ï¼‰
7. å®šä¹‰æ‰¹æ¬¡å¤§å°å’Œé™åˆ¶

**ç¦æ­¢åš**:
- ä¸è¦åœ¨å…¶ä»–æ¨¡å—ä¸­ç¡¬ç¼–ç å€¼
- ä¸è¦åˆ›å»ºå¾ªç¯ä¾èµ–

**æ¨èä»£ç†é…ç½®**:
- **åˆ†ç±»**: quick
- **åŸå› **: ç®€å•çš„å¸¸é‡å®šä¹‰ï¼Œå¤æ‚åº¦ä½
- **æŠ€èƒ½**: ä¸éœ€è¦

**å¹¶è¡ŒåŒ–**:
- **å¯å¹¶è¡Œè¿è¡Œ**: æ˜¯ - æ³¢æ¬¡ 1
- **é˜»å¡**: ä»»åŠ¡ 4, 5 (èšç±»ã€ä¿¡å·æ£€æµ‹)
- **è¢«é˜»å¡äº**: æ— 

**å‚è€ƒ**:
- WorldMonitor: `analysis-constants.ts` ç”¨äºåœç”¨è¯ã€ä¸»é¢˜å…³é”®è¯ã€é˜ˆå€¼
- WorldMonitor: `analysis-core.ts` ç”¨äºä¿¡å·ç±»å‹å®šä¹‰
- ç°æœ‰: `scripts/crawler.py` ç”¨äºæ‰¹æ¬¡å¤§å°æ¨¡å¼

**éªŒæ”¶æ ‡å‡†**:

**ä»£ç†æ‰§è¡Œçš„ QA åœºæ™¯:**

```
åœºæ™¯: é…ç½®æ­£ç¡®åŠ è½½
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. è¿è¡Œ: python -c "from config.analysis_config import SIMILARITY_THRESHOLD, STOP_WORDS; print(f'Threshold: {SIMILARITY_THRESHOLD}')"
    2. æ–­è¨€: é€€å‡ºä»£ç  0
    3. æ–­è¨€: è¾“å‡ºæ˜¾ç¤ºé˜ˆå€¼ (0.5)

åœºæ™¯: åœç”¨è¯å·²å®šä¹‰
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. è¿è¡Œ: python -c "from config.analysis_config import STOP_WORDS; print(f'Count: {len(STOP_WORDS)}')"
    2. æ–­è¨€: STOP_WORDS åŒ…å«å¸¸è§è¯ (the, a, an, and)
    3. æ–­è¨€: æ•°é‡ > 20
    4. è¯æ®: æ‰“å°åœç”¨è¯ç¤ºä¾‹

åœºæ™¯: ä¸»é¢˜å…³é”®è¯å·²åˆ†ç±»
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. è¿è¡Œ: python -c "from config.analysis_config import TOPIC_KEYWORDS; print(TOPIC_KEYWORDS)"
    2. æ–­è¨€: æœ‰é”®: 'military', 'politics', 'economy'
    3. æ–­è¨€: æ¯ä¸ªåˆ†ç±»æœ‰ 10+ å…³é”®è¯
    4. è¯æ®: ä¿å­˜è¾“å‡º

åœºæ™¯: LLM æç¤ºè¯å·²å®šä¹‰
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. è¿è¡Œ: python -c "from config.analysis_config import LLM_PROMPTS; print(LLM_PROMPTS.keys())"
    2. æ–­è¨€: åŒ…å« 'cluster_summary' é”®
    3. æ–­è¨€: æç¤ºè¯æ˜¯éç©ºå­—ç¬¦ä¸²ï¼ŒåŒ…å«æŒ‡ä»¤
    4. è¯æ®: ä¿å­˜æç¤ºè¯å†…å®¹
```

**æäº¤**: æ˜¯
- æ¶ˆæ¯: `feat(config): add analysis configuration with thresholds and prompts`
- æ–‡ä»¶: `config/analysis_config.py`, `config/__init__.py`
- æäº¤å‰: éªŒè¯å¯¼å…¥æœ‰æ•ˆ

---

### ä»»åŠ¡ 4: èšç±»å¼•æ“

**åšä»€ä¹ˆ**:
å®ç° Jaccard ç›¸ä¼¼åº¦èšç±»ï¼ˆçº¯å‡½æ•°ï¼‰:
1. `scripts/clustering.py` - æ ¸å¿ƒèšç±»é€»è¾‘
2. `tokenize(title)` - å¸¦åœç”¨è¯å»é™¤çš„åˆ†è¯
3. `jaccard_similarity(set1, set2)` - ç›¸ä¼¼åº¦è®¡ç®—
4. `cluster_news(articles)` - å¸¦å€’æ’ç´¢å¼•ä¼˜åŒ–çš„ä¸»èšç±»
5. åŸºäºå†…å®¹å“ˆå¸Œç”Ÿæˆèšç±» ID
6. æŒ‰æ¥æºå±‚çº§å’Œæ—¶æ•ˆæ€§æ’åºèšç±»
7. è¿”å›å¸¦å…ƒæ•°æ®çš„èšç±»å¯¹è±¡

**ç¦æ­¢åš**:
- ä¸è¦ä½¿ç”¨ scikit-learn æˆ–å¤–éƒ¨ ML åº“ï¼ˆä¿æŒçº¯ Pythonï¼‰
- ä¸è¦æ”¹å˜è¾“å…¥æ–‡ç« 
- ä¸è¦è®¿é—®æ•°æ®åº“ï¼ˆçº¯å‡½æ•°ï¼‰

**æ¨èä»£ç†é…ç½®**:
- **åˆ†ç±»**: unspecified-high
- **åŸå› **: ç®—æ³•å®ç°éœ€è¦ä»”ç»†ä¼˜åŒ–ï¼Œç®¡ç† O(nÂ²) å¤æ‚åº¦
- **æŠ€èƒ½**: ä¸éœ€è¦ï¼ˆçº¯ Python ç®—æ³•ï¼‰

**å¹¶è¡ŒåŒ–**:
- **å¯å¹¶è¡Œè¿è¡Œ**: æ˜¯ - æ³¢æ¬¡ 2
- **é˜»å¡**: ä»»åŠ¡ 6 (ä¸»åˆ†æå™¨)
- **è¢«é˜»å¡äº**: ä»»åŠ¡ 3 (é…ç½®)

**å‚è€ƒ**:
- WorldMonitor: `analysis-core.ts:154-280` - clusterNewsCore å®ç°
- WorldMonitor: `analysis-constants.ts:59-73` - tokenize å’Œ jaccardSimilarity
- æ¨¡å¼: ç”¨äº O(n) å€™é€‰é€‰æ‹©çš„å€’æ’ç´¢å¼•ï¼Œè€Œé O(nÂ²) æ¯”è¾ƒ

**éªŒæ”¶æ ‡å‡†**:

**ä»£ç†æ‰§è¡Œçš„ QA åœºæ™¯:**

```
åœºæ™¯: åˆ†è¯æ­£ç¡®å·¥ä½œ
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. è¿è¡Œ: python -c "from scripts.clustering import tokenize; print(tokenize('The quick brown fox'))"
    2. æ–­è¨€: è¿”å›ä¸å«åœç”¨è¯ (the) çš„é›†åˆ
    3. æ–­è¨€: åŒ…å« 'quick', 'brown', 'fox'
    4. è¯æ®: è¾“å‡ºæ˜¾ç¤ºæ­£ç¡®çš„ token

åœºæ™¯: Jaccard ç›¸ä¼¼åº¦æ­£ç¡®è®¡ç®—
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. è¿è¡Œ: python -c "from scripts.clustering import jaccard_similarity; print(jaccard_similarity({'a','b'}, {'a','b'}))"
    2. æ–­è¨€: ç›¸åŒé›†åˆè¿”å› 1.0
    3. ç”¨ {'a','b'}, {'c','d'} è¿è¡Œ
    4. æ–­è¨€: ä¸ç›¸äº¤é›†åˆè¿”å› 0.0
    5. è¯æ®: æµ‹è¯•ç»“æœæˆªå›¾

åœºæ™¯: èšç±»å°†ç›¸ä¼¼æ–‡ç« åˆ†ç»„
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. åˆ›å»º 5 ç¯‡æ–‡ç« çš„æµ‹è¯•æ•°æ®ï¼ˆ3 ç¯‡ç›¸ä¼¼ï¼Œ2 ç¯‡ä¸åŒï¼‰
    2. è¿è¡Œ: python -c "from scripts.clustering import cluster_news; import json; clusters = cluster_news(test_data); print(f'Clusters: {len(clusters)}')"
    3. æ–­è¨€: åˆ›å»º 2-3 ä¸ªèšç±»ï¼ˆä¸æ˜¯ 5 ä¸ªç‹¬ç«‹çš„ï¼‰
    4. æ–­è¨€: ç›¸ä¼¼æ–‡ç« åˆ†ç»„åœ¨ä¸€èµ·
    5. è¯æ®: æ‰“å°èšç±»åˆ†é…

åœºæ™¯: å€’æ’ç´¢å¼•ä¼˜åŒ–æœ‰æ•ˆ
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. ç”¨ 100 ç¯‡æ–‡ç« æµ‹è¯•
    2. æµ‹é‡æœ‰å’Œæ²¡æœ‰å€’æ’ç´¢å¼•çš„æ—¶é—´
    3. æ–­è¨€: æœ‰å€’æ’ç´¢å¼•æ˜¾è‘—æ›´å¿«
    4. è¯æ®: ä¿å­˜æ—¶é—´æ—¥å¿—
```

**æäº¤**: æ˜¯
- æ¶ˆæ¯: `feat(clustering): implement Jaccard similarity clustering with inverted index`
- æ–‡ä»¶: `scripts/clustering.py`
- æäº¤å‰: å•å…ƒæµ‹è¯•é€šè¿‡

---

### ä»»åŠ¡ 5: ä¿¡å·æ£€æµ‹

**åšä»€ä¹ˆ**:
å®ç°ä¿¡å·æ£€æµ‹ç®—æ³•:
1. `scripts/signal_detector.py` - ä¿¡å·æ£€æµ‹æ¨¡å—
2. `detect_velocity_spike(clusters)` - æ–°é—»é€Ÿåº¦æ¿€å¢æ£€æµ‹
3. `detect_convergence(clusters)` - å¤šæ¥æºç±»å‹ç¡®è®¤
4. `detect_triangulation(clusters)` - é€šè®¯ç¤¾+æ”¿åºœ+æƒ…æŠ¥å¯¹é½
5. `detect_hotspot_escalation(clusters)` - å¤åˆå‡çº§è¯„åˆ†
6. `generate_signal_id()`, `generate_dedupe_key()` - å·¥å…·å‡½æ•°
7. è¿”å›å¸¦ç½®ä¿¡åº¦è¯„åˆ†çš„ä¿¡å·å¯¹è±¡

**ç¦æ­¢åš**:
- ä¸è¦å®ç° prediction_leads_news æˆ– news_leads_marketsï¼ˆæ— å¸‚åœºæ•°æ®ï¼‰
- ä¸è¦å®ç° flow_drop æˆ– flow_price_divergenceï¼ˆæ— ç®¡é“æ•°æ®ï¼‰
- ä¸è¦è®¿é—®å¤–éƒ¨ API

**æ¨èä»£ç†é…ç½®**:
- **åˆ†ç±»**: unspecified-high
- **åŸå› **: ç®—æ³•é€»è¾‘éœ€è¦ä»”ç»†çš„é˜ˆå€¼è°ƒæ•´å’Œæƒé‡è®¡ç®—
- **æŠ€èƒ½**: ä¸éœ€è¦

**å¹¶è¡ŒåŒ–**:
- **å¯å¹¶è¡Œè¿è¡Œ**: æ˜¯ - æ³¢æ¬¡ 2
- **é˜»å¡**: ä»»åŠ¡ 6 (ä¸»åˆ†æå™¨)
- **è¢«é˜»å¡äº**: ä»»åŠ¡ 3 (é…ç½®)

**å‚è€ƒ**:
- WorldMonitor: `analysis-core.ts:302-434` - detectPipelineFlowDrops, detectConvergence, detectTriangulation
- WorldMonitor: `hotspot-escalation.ts` - å¸¦åŠ æƒç»„ä»¶çš„å‡çº§è¯„åˆ†
- WorldMonitor: `analysis-constants.ts` - ç”¨äºè§£é‡Šçš„ SIGNAL_CONTEXT

**éªŒæ”¶æ ‡å‡†**:

**ä»£ç†æ‰§è¡Œçš„ QA åœºæ™¯:**

```
åœºæ™¯: æ£€æµ‹åˆ°é€Ÿåº¦æ¿€å¢
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. åˆ›å»ºæµ‹è¯•èšç±»ï¼Œå…¶ä¸­ä¸€ä¸ªèšç±»åœ¨ 1 å°æ—¶å†…æœ‰ 10+ ä¸ªæ¥æº
    2. è¿è¡Œ: python -c "from scripts.signal_detector import detect_velocity_spike; signals = detect_velocity_spike(clusters)"
    3. æ–­è¨€: è¿”å› velocity_spike ä¿¡å·
    4. æ–­è¨€: ç½®ä¿¡åº¦ > 0.6
    5. è¯æ®: æ‰“å°ä¿¡å·è¯¦æƒ…

åœºæ™¯: æ£€æµ‹åˆ°æ±‡èš
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. ç”¨ 3+ ä¸ªä¸åŒæ¥æºç±»å‹åˆ›å»ºæµ‹è¯•èšç±»
    2. è¿è¡Œ: python -c "from scripts.signal_detector import detect_convergence; signals = detect_convergence(clusters)"
    3. æ–­è¨€: è¿”å› convergence ä¿¡å·
    4. æ–­è¨€: æè¿°ä¸­åˆ—å‡ºæ¥æºç±»å‹
    5. è¯æ®: ä¿å­˜ä¿¡å·è¾“å‡º

åœºæ™¯: æ£€æµ‹åˆ°ä¸‰è§’å®šä½
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. ç”¨é€šè®¯ç¤¾ + æ”¿åºœ + æƒ…æŠ¥æ¥æºåˆ›å»ºæµ‹è¯•èšç±»
    2. è¿è¡Œ: python -c "from scripts.signal_detector import detect_triangulation; signals = detect_triangulation(clusters)"
    3. æ–­è¨€: è¿”å› triangulation ä¿¡å·
    4. æ–­è¨€: ç½®ä¿¡åº¦ >= 0.9
    5. è¯æ®: æˆªå›¾

åœºæ™¯: ä¿¡å·å»é‡æœ‰æ•ˆ
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. ç”¨ç›¸åŒèšç±»è°ƒç”¨ detect_velocity_spike ä¸¤æ¬¡
    2. æ–­è¨€: generate_dedupe_key å¯¹ç›¸åŒè¾“å…¥è¿”å›ç›¸åŒé”®
    3. æ–­è¨€: ç¬¬äºŒæ¬¡è°ƒç”¨ä¼šè¢«å»é‡é€»è¾‘è¿‡æ»¤
    4. è¯æ®: æ˜¾ç¤ºå»é‡é”®åŒ¹é…
```

**æäº¤**: æ˜¯
- æ¶ˆæ¯: `feat(signals): implement velocity, convergence, triangulation detection`
- æ–‡ä»¶: `scripts/signal_detector.py`
- æäº¤å‰: å•å…ƒæµ‹è¯•é€šè¿‡

---

### ä»»åŠ¡ 6: ä¸»åˆ†æå™¨æµæ°´çº¿

**åšä»€ä¹ˆ**:
åˆ›å»ºä¸»åˆ†æç¼–æ’å™¨:
1. `scripts/analyzer.py` - ä¸»å…¥å£ç‚¹
2. ä» Supabase åŠ è½½æœªåˆ†æçš„æ–‡ç« ï¼ˆWHERE analyzed_at IS NULLï¼‰
3. æŒ‰æ—¶é—´çª—å£è¿‡æ»¤ï¼ˆæœ€è¿‘ 24 å°æ—¶ï¼‰
4. å¯¹æ–‡ç« è¿è¡Œèšç±»
5. è°ƒç”¨ LLM è¿›è¡Œèšç±»æ€»ç»“ï¼ˆæ‰¹é‡è°ƒç”¨ï¼‰
6. å¯¹èšç±»è¿è¡Œä¿¡å·æ£€æµ‹
7. å°†ç»“æœå­˜å‚¨åˆ°æ•°æ®åº“ï¼ˆèšç±»ã€ä¿¡å·ã€æ ‡è®°æ–‡ç« ä¸ºå·²åˆ†æï¼‰
8. æ—¥å¿—å’Œè¿›åº¦è·Ÿè¸ª
9. éƒ¨åˆ†æˆåŠŸçš„é”™è¯¯å¤„ç†

**ç¦æ­¢åš**:
- æ¯æ¬¡è¿è¡Œä¸è¦å¤„ç†è¶…è¿‡ 500 ç¯‡æ–‡ç« 
- æ¯æ¬¡è¿è¡Œä¸è¦è¿›è¡Œè¶…è¿‡ 200 æ¬¡ LLM API è°ƒç”¨
- å¦‚æœå•ä¸ªæ–‡ç« /èšç±»å¤±è´¥ï¼Œä¸è¦å®Œå…¨å¤±è´¥

**æ¨èä»£ç†é…ç½®**:
- **åˆ†ç±»**: ultrabrain
- **åŸå› **: å¤æ‚çš„ç¼–æ’ã€æ•°æ®åº“äº‹åŠ¡ã€API é€Ÿç‡é™åˆ¶ã€æ‰¹å¤„ç†ã€é”™è¯¯æ¢å¤
- **æŠ€èƒ½**: ä¸éœ€è¦

**å¹¶è¡ŒåŒ–**:
- **å¯å¹¶è¡Œè¿è¡Œ**: å¦ - æ³¢æ¬¡ 3
- **é˜»å¡**: ä»»åŠ¡ 7 (GitHub Actions)
- **è¢«é˜»å¡äº**: ä»»åŠ¡ 1, 2, 4, 5

**å‚è€ƒ**:
- WorldMonitor: `analysis.worker.ts` - worker æ¶ˆæ¯å¤„ç†å’ŒçŠ¶æ€ç®¡ç†
- ç°æœ‰: `scripts/crawler.py` - æ‰¹å¤„ç†æ¨¡å¼ã€Supabase äº¤äº’
- ç°æœ‰: `scripts/dedup.py` - SimHash å®ç°ï¼ˆçº¯å‡½æ•°å‚è€ƒï¼‰

**éªŒæ”¶æ ‡å‡†**:

**ä»£ç†æ‰§è¡Œçš„ QA åœºæ™¯:**

```
åœºæ™¯: åˆ†æå™¨ç«¯åˆ°ç«¯è¿è¡Œ
  å·¥å…·: Bash (python)
  å‰ç½®æ¡ä»¶: æ•°æ®åº“ä¸­æœ‰æµ‹è¯•æ–‡ç« ï¼ŒAPI key å·²é…ç½®
  æ­¥éª¤:
    1. è¿è¡Œ: python scripts/analyzer.py --limit 10
    2. æ–­è¨€: é€€å‡ºä»£ç  0
    3. æ–­è¨€: æ—¥å¿—æ˜¾ç¤º: "Loaded 10 unanalyzed articles"
    4. æ–­è¨€: æ—¥å¿—æ˜¾ç¤º: "Created X clusters"
    5. æ–­è¨€: æ—¥å¿—æ˜¾ç¤º: "Detected Y signals"
    6. è¯æ®: ä¿å­˜å®Œæ•´æ—¥å¿—è¾“å‡º

åœºæ™¯: æ–‡ç« æ ‡è®°ä¸ºå·²åˆ†æ
  å·¥å…·: Bash (psql)
  æ­¥éª¤:
    1. æŸ¥è¯¢: SELECT COUNT(*) FROM articles WHERE analyzed_at IS NOT NULL
    2. æ–­è¨€: è®¡æ•°ç­‰äºå·²å¤„ç†æ–‡ç« æ•° (10)
    3. æŸ¥è¯¢: SELECT analyzed_at FROM articles LIMIT 1
    4. æ–­è¨€: æ—¶é—´æˆ³æ˜¯æœ€è¿‘çš„
    5. è¯æ®: æŸ¥è¯¢ç»“æœæˆªå›¾

åœºæ™¯: èšç±»å­˜å‚¨åœ¨æ•°æ®åº“ä¸­
  å·¥å…·: Bash (psql)
  æ­¥éª¤:
    1. æŸ¥è¯¢: SELECT COUNT(*) FROM analysis_clusters
    2. æ–­è¨€: è®¡æ•° > 0
    3. æŸ¥è¯¢: SELECT * FROM analysis_clusters LIMIT 1
    4. æ–­è¨€: æœ‰ summary, category, article_count
    5. è¯æ®: ä¿å­˜æŸ¥è¯¢è¾“å‡º

åœºæ™¯: ä¿¡å·å­˜å‚¨åœ¨æ•°æ®åº“ä¸­
  å·¥å…·: Bash (psql)
  æ­¥éª¤:
    1. æŸ¥è¯¢: SELECT COUNT(*) FROM analysis_signals
    2. æ–­è¨€: è®¡æ•° >= 0ï¼ˆå¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°ä¿¡å·å¯èƒ½ä¸º 0ï¼‰
    3. æŸ¥è¯¢: SELECT * FROM analysis_signals LIMIT 1
    4. æ–­è¨€: å¦‚æœå­˜åœ¨ï¼Œæœ‰ signal_type, confidence, description
    5. è¯æ®: ä¿å­˜è¾“å‡º

åœºæ™¯: éµå®ˆ limit å‚æ•°
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. ç”¨ --limit 5 è¿è¡Œ
    2. æ–­è¨€: æ—¥å¿—æ˜¾ç¤º "Processing max 5 articles"
    3. æ–­è¨€: åªæœ‰ 5 ç¯‡æ–‡ç« æ ‡è®°ä¸ºå·²åˆ†æ
    4. è¯æ®: æ¯”è¾ƒä¹‹å‰/ä¹‹åçš„è®¡æ•°

åœºæ™¯: ä¼˜é›…åœ°å¤„ç†é”™è¯¯
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. ä¸´æ—¶ç ´åä¸€ç¯‡æ–‡ç« ï¼ˆç©ºå†…å®¹ï¼‰
    2. è¿è¡Œ: python scripts/analyzer.py
    3. æ–­è¨€: æµæ°´çº¿å®Œæˆï¼ˆé€€å‡º 0ï¼‰
    4. æ–­è¨€: æ—¥å¿—æ˜¾ç¤º "Skipped 1 invalid articles"
    5. æ–­è¨€: å…¶ä»–æ–‡ç« ä»è¢«å¤„ç†
    6. è¯æ®: æ˜¾ç¤ºé”™è¯¯å¤„ç†çš„æ—¥å¿—
```

**æäº¤**: æ˜¯
- æ¶ˆæ¯: `feat(analyzer): add main analysis pipeline with clustering and LLM`
- æ–‡ä»¶: `scripts/analyzer.py`
- æäº¤å‰: ç”¨ --limit 10 å®Œæ•´æµ‹è¯•è¿è¡Œ

---

### ä»»åŠ¡ 7: GitHub Actions å·¥ä½œæµ

**åšä»€ä¹ˆ**:
ä¸ºè‡ªåŠ¨åŒ–åˆ†æåˆ›å»º GitHub Actions å·¥ä½œæµ:
1. `.github/workflows/analyzer.yml` - å·¥ä½œæµå®šä¹‰
2. è§¦å‘å™¨: scheduleï¼ˆçˆ¬è™«è¿è¡Œå 1 å°æ—¶ï¼‰+ workflow_dispatch
3. è®¾ç½® Python ç¯å¢ƒ
4. å®‰è£…ä¾èµ–
5. ç”¨æ­£ç¡®çš„ç¯å¢ƒå˜é‡è¿è¡Œåˆ†æå™¨
6. å¤±è´¥æ—¶é”™è¯¯é€šçŸ¥
7. æ—¥å¿—äº§ç‰©ä¸Šä¼ 

**ç¦æ­¢åš**:
- ä¸è¦ä¸çˆ¬è™«å·¥ä½œæµåˆå¹¶ï¼ˆä¿æŒåˆ†ç¦»ï¼‰
- ä¸è¦åœ¨æ¯æ¬¡æ¨é€æ—¶è§¦å‘ï¼ˆä»… scheduleï¼‰

**æ¨èä»£ç†é…ç½®**:
- **åˆ†ç±»**: quick
- **åŸå› **: YAML é…ç½®ï¼Œç›´æ¥çš„å·¥ä½œæµè®¾ç½®
- **æŠ€èƒ½**: ä¸éœ€è¦

**å¹¶è¡ŒåŒ–**:
- **å¯å¹¶è¡Œè¿è¡Œ**: å¦ - æ³¢æ¬¡ 3
- **é˜»å¡**: ä»»åŠ¡ 8 (ç«¯åˆ°ç«¯æµ‹è¯•)
- **è¢«é˜»å¡äº**: ä»»åŠ¡ 6 (ä¸»åˆ†æå™¨)

**å‚è€ƒ**:
- ç°æœ‰: `.github/workflows/crawler.yml` - å·¥ä½œæµç»“æ„
- WorldMonitor: ä¸é€‚ç”¨ï¼ˆä»–ä»¬ä½¿ç”¨ Web Workersï¼Œä¸æ˜¯ GitHub Actionsï¼‰

**éªŒæ”¶æ ‡å‡†**:

**ä»£ç†æ‰§è¡Œçš„ QA åœºæ™¯:**

```
åœºæ™¯: å·¥ä½œæµæ–‡ä»¶æ˜¯æœ‰æ•ˆçš„ YAML
  å·¥å…·: Bash
  æ­¥éª¤:
    1. è¿è¡Œ: python -c "import yaml; yaml.safe_load(open('.github/workflows/analyzer.yml'))"
    2. æ–­è¨€: é€€å‡ºä»£ç  0
    3. æ–­è¨€: æ—  YAML è¯­æ³•é”™è¯¯

åœºæ™¯: å·¥ä½œæµæŒ‰è®¡åˆ’è§¦å‘
  å·¥å…·: Read (file)
  æ­¥éª¤:
    1. è¯»å–: .github/workflows/analyzer.yml
    2. æ–­è¨€: åŒ…å«å¸¦ cron è¡¨è¾¾å¼çš„ 'schedule:'
    3. æ–­è¨€: Cron åœ¨çˆ¬è™«è°ƒåº¦å 1 å°æ—¶ï¼ˆä¸Šåˆ 10 ç‚¹/æ™šä¸Š 10 ç‚¹ç¾ä¸œæ—¶é—´ï¼‰
    4. æ–­è¨€: ä¹Ÿæœ‰ç”¨äºæ‰‹åŠ¨è¿è¡Œçš„ 'workflow_dispatch:'
    5. è¯æ®: schedule éƒ¨åˆ†æˆªå›¾

åœºæ™¯: å·¥ä½œæµæˆåŠŸè¿è¡Œï¼ˆæ‰‹åŠ¨è§¦å‘ï¼‰
  å·¥å…·: Web (GitHub Actions é¡µé¢)
  æ­¥éª¤:
    1. å‰å¾€ GitHub ä»“åº“ â†’ Actions â†’ Analyzer å·¥ä½œæµ
    2. ç‚¹å‡» "Run workflow"
    3. ç­‰å¾…å®Œæˆ
    4. æ–­è¨€: å·¥ä½œæµæ˜¾ç¤ºç»¿è‰²å‹¾é€‰æ ‡è®°
    5. æ–­è¨€: æ—¥å¿—æ˜¾ç¤ºåˆ†æå™¨å·²æ‰§è¡Œ
    6. è¯æ®: æˆåŠŸè¿è¡Œæˆªå›¾

åœºæ™¯: ç¯å¢ƒå˜é‡å·²é…ç½®
  å·¥å…·: Bash
  æ­¥éª¤:
    1. æ£€æŸ¥: GitHub Settings â†’ Secrets
    2. æ–­è¨€: ALIBABA_API_KEY secret å­˜åœ¨
    3. æ–­è¨€: SUPABASE_URL secret å­˜åœ¨
    4. æ–­è¨€: SUPABASE_KEY secret å­˜åœ¨
    5. è¯æ®: secret åˆ—è¡¨ï¼ˆå€¼å·²è„±æ•ï¼‰
```

**æäº¤**: æ˜¯
- æ¶ˆæ¯: `ci(actions): add analyzer workflow for automated hotspot detection`
- æ–‡ä»¶: `.github/workflows/analyzer.yml`
- æäº¤å‰: éªŒè¯ YAML è¯­æ³•

---

### ä»»åŠ¡ 8: ç«¯åˆ°ç«¯æµ‹è¯•

**åšä»€ä¹ˆ**:
å…¨é¢çš„ç«¯åˆ°ç«¯éªŒè¯:
1. åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šè¿è¡Œå®Œæ•´æµæ°´çº¿
2. éªŒè¯ä¹‹å‰/ä¹‹åçš„æ•°æ®åº“çŠ¶æ€
3. éªŒè¯èšç±»è´¨é‡ï¼ˆä¸è¦å¤ªå¤šï¼Œä¸è¦å¤ªå°‘ï¼‰
4. æ£€æŸ¥ä¿¡å·æ£€æµ‹å‡†ç¡®æ€§
5. éªŒè¯ LLM è¾“å‡ºè´¨é‡
6. æ€§èƒ½æ£€æŸ¥ï¼ˆåœ¨ <30 åˆ†é’Ÿå†…å®Œæˆï¼‰
7. åˆ›å»ºæµ‹è¯•æŠ¥å‘Š

**ç¦æ­¢åš**:
- ä¸è¦ä¿®æ”¹ç”Ÿäº§æ•°æ®
- ä¸è¦è·³è¿‡é”™è¯¯åœºæ™¯

**æ¨èä»£ç†é…ç½®**:
- **åˆ†ç±»**: unspecified-high
- **åŸå› **: è·¨å¤šä¸ªç»„ä»¶çš„å¤æ‚éªŒè¯ï¼Œæ•°æ®åº“çŠ¶æ€éªŒè¯ï¼Œè´¨é‡æŒ‡æ ‡
- **æŠ€èƒ½**: ä¸éœ€è¦

**å¹¶è¡ŒåŒ–**:
- **å¯å¹¶è¡Œè¿è¡Œ**: å¦ - æ³¢æ¬¡ 4
- **é˜»å¡**: æ— ï¼ˆæœ€ç»ˆä»»åŠ¡ï¼‰
- **è¢«é˜»å¡äº**: ä»»åŠ¡ 7 (GitHub Actions)

**å‚è€ƒ**:
- æ‰€æœ‰ä¹‹å‰çš„ä»»åŠ¡
- WorldMonitor: `analysis-core.ts` éªŒæ”¶æ¨¡å¼

**éªŒæ”¶æ ‡å‡†**:

**ä»£ç†æ‰§è¡Œçš„ QA åœºæ™¯:**

```
åœºæ™¯: ç«¯åˆ°ç«¯æµæ°´çº¿æˆåŠŸ
  å·¥å…·: Bash (GitHub Actions æˆ–æœ¬åœ°)
  æ­¥éª¤:
    1. è§¦å‘åˆ†æå™¨å·¥ä½œæµ
    2. ç­‰å¾…å®Œæˆ
    3. æ–­è¨€: çŠ¶æ€ä¸º "success"
    4. æ–­è¨€: æŒç»­æ—¶é—´ < 30 åˆ†é’Ÿ
    5. è¯æ®: å·²å®Œæˆè¿è¡Œçš„æˆªå›¾

åœºæ™¯: æ•°æ®åº“æ˜¾ç¤ºåˆ†æç»“æœ
  å·¥å…·: Bash (psql)
  æ­¥éª¤:
    1. æŸ¥è¯¢: SELECT COUNT(*) FROM analysis_clusters WHERE created_at > NOW() - INTERVAL '1 hour'
    2. æ–­è¨€: è®¡æ•° > 0
    3. æŸ¥è¯¢: SELECT AVG(article_count) FROM analysis_clusters
    4. æ–­è¨€: å¹³å‡å€¼åœ¨ 3-10 ä¹‹é—´ï¼ˆåˆç†çš„èšç±»å¤§å°ï¼‰
    5. è¯æ®: æŸ¥è¯¢ç»“æœ

åœºæ™¯: èšç±»è´¨é‡è‰¯å¥½
  å·¥å…·: Bash (psql)
  æ­¥éª¤:
    1. æŸ¥è¯¢: SELECT COUNT(DISTINCT cluster_id) FROM article_analyses
    2. æ–­è¨€: èšç±»æ•°é‡åˆç†ï¼ˆ1000 ç¯‡æ–‡ç« å¯¹åº” 50-200 ä¸ªï¼‰
    3. æŸ¥è¯¢: æŸ¥æ‰¾æœ€å¤§çš„èšç±»
    4. æ–­è¨€: æ²¡æœ‰èšç±»æœ‰ >50 ç¯‡æ–‡ç« ï¼ˆè¡¨ç¤ºè¿‡åº¦èšç±»ï¼‰
    5. è¯æ®: åˆ†å¸ƒç»Ÿè®¡

åœºæ™¯: LLM æ€»ç»“æœ‰æ•ˆ
  å·¥å…·: Bash (psql)
  æ­¥éª¤:
    1. æŸ¥è¯¢: SELECT summary FROM analysis_clusters LIMIT 3
    2. æ–­è¨€: æ€»ç»“éç©º
    3. æ–­è¨€: æ€»ç»“æ˜¯è¿è´¯çš„è‹±æ–‡æ–‡æœ¬
    4. æ–­è¨€: é•¿åº¦ä¸º 100-500 å­—ç¬¦ï¼ˆåˆç†ï¼‰
    5. è¯æ®: ä¿å­˜ç¤ºä¾‹æ€»ç»“

åœºæ™¯: å¢é‡å¤„ç†æœ‰æ•ˆ
  å·¥å…·: Bash (python + psql)
  æ­¥éª¤:
    1. ä¹‹å‰ç»Ÿè®¡æœªåˆ†ææ–‡ç« æ•°: SELECT COUNT(*) FROM articles WHERE analyzed_at IS NULL
    2. è¿è¡Œåˆ†æå™¨
    3. ä¹‹åç»Ÿè®¡: åº”è¯¥ä¸º 0ï¼ˆæˆ–æ¥è¿‘ 0ï¼‰
    4. ç«‹å³å†æ¬¡è¿è¡Œåˆ†æå™¨
    5. æ–­è¨€: ç¬¬äºŒæ¬¡è¿è¡Œå¤„ç† 0 ç¯‡æ–‡ç« ï¼ˆå…¨éƒ¨å·²åˆ†æï¼‰
    6. è¯æ®: ä¹‹å‰/ä¹‹åçš„è®¡æ•°

åœºæ™¯: é”™è¯¯åœºæ™¯å·²å¤„ç†
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. æ³¨å…¥ä¸è‰¯æ•°æ®: æ’å…¥ç©ºå†…å®¹çš„æ–‡ç« 
    2. è¿è¡Œåˆ†æå™¨
    3. æ–­è¨€: å®Œæˆä¸å´©æºƒ
    4. æ–­è¨€: æ—¥å¿—æ˜¾ç¤ºé”™è¯¯ä½†ç»§ç»­
    5. æ–­è¨€: æœ‰æ•ˆæ–‡ç« ä»è¢«å¤„ç†
    6. è¯æ®: é”™è¯¯æ—¥å¿—æˆªå›¾
```

**æäº¤**: æ˜¯
- æ¶ˆæ¯: `test(e2e): add end-to-end validation and test report`
- æ–‡ä»¶: `tests/test_analyzer_e2e.py`, `tests/report.md`
- æäº¤å‰: æ‰€æœ‰æµ‹è¯•é€šè¿‡

---

### ä»»åŠ¡ 9: å…è´¹æ•°æ®æºé›†æˆï¼ˆFree Data Sourcesï¼‰

**åšä»€ä¹ˆ**:
é›†æˆ worldmonitor ä¸­å¯ç”¨çš„å…è´¹/ä½æˆæœ¬æ•°æ®æºï¼Œå¢å¼ºåˆ†æç»´åº¦ï¼š

1. **FRED ç¾å›½ç»æµæ•°æ®** (`scripts/datasources/fred_client.py`)
   - å…è´¹ APIï¼Œéœ€ç”³è¯· API key (https://fred.stlouisfed.org/docs/api/api_key.html)
   - è·å–æŒ‡æ ‡ï¼šè”é‚¦åŸºé‡‘åˆ©ç‡ã€CPIã€å¤±ä¸šç‡ã€GDP ç­‰
   - ç”¨é€”ï¼šç»æµæ•°æ®ä¿¡å·å¢å¼º

2. **GDELT å…¨çƒäº‹ä»¶æ•°æ®åº“** (`scripts/datasources/gdelt_client.py`)
   - å®Œå…¨å…è´¹ï¼Œæ— éœ€ API key
   - è·å–å…¨çƒäº‹ä»¶åœ°ç†åˆ†å¸ƒæ•°æ®
   - ç”¨é€”ï¼šåœ°ç¼˜æ”¿æ²»äº‹ä»¶å¼ºåº¦è¯„ä¼°

3. **USGS åœ°éœ‡æ•°æ®** (`scripts/datasources/earthquake_client.py`)
   - å®Œå…¨å…è´¹ï¼Œæ— éœ€ API key
   - è·å– 4.5 çº§ä»¥ä¸Šåœ°éœ‡æ•°æ®
   - ç”¨é€”ï¼šè‡ªç„¶ç¾å®³ä¿¡å·æ£€æµ‹

4. **World Bank æŒ‡æ ‡** (`scripts/datasources/worldbank_client.py`)
   - å®Œå…¨å…è´¹ï¼Œæ— éœ€ API key
   - è·å–å„å›½ç»æµæŒ‡æ ‡ï¼šGDPã€æ•™è‚²ã€ç ”å‘æ”¯å‡ºç­‰
   - ç”¨é€”ï¼šå›½å®¶ç¨³å®šæ€§è¯„ä¼°

5. **å¢å¼ºä¿¡å·æ£€æµ‹å™¨** (`scripts/datasources/enhanced_signals.py`)
   - ç»“åˆå¤šæ•°æ®æºç”Ÿæˆå¢å¼ºä¿¡å·
   - æ–°å¢ä¿¡å·ç±»å‹ï¼š
     - `economic_indicator_alert` - å…³é”®ç»æµæŒ‡æ ‡å¼‚å¸¸
     - `natural_disaster_signal` - è‡ªç„¶ç¾å®³ç›¸å…³æ–°é—»
     - `geopolitical_intensity` - åœ°ç¼˜æ”¿æ²»äº‹ä»¶å¼ºåº¦

**ç¦æ­¢åš**:
- ä¸è¦è°ƒç”¨ä»˜è´¹ APIï¼ˆå¦‚ ACLED éœ€è¦ä»˜è´¹ tokenï¼‰
- ä¸è¦å­˜å‚¨å¤§é‡å†å²æ•°æ®ï¼ˆåªä¿ç•™æœ€è¿‘ 30 å¤©ï¼‰
- ä¸è¦å®æ—¶è½®è¯¢ï¼ˆåœ¨åˆ†ææ—¶æ‰¹é‡è·å–ï¼‰

**æ¨èä»£ç†é…ç½®**:
- **åˆ†ç±»**: unspecified-high
- **åŸå› **: Multiple API integrations, data transformation, caching
- **æŠ€èƒ½**: None needed

**å¹¶è¡ŒåŒ–**:
- **å¯å¹¶è¡Œè¿è¡Œ**: YES - Wave 5 (ä¸ Task 10 å¹¶è¡Œ)
- **é˜»å¡**: Task 11 (Enhanced Analyzer)
- **è¢«é˜»å¡äº**: Task 3 (Configuration)

**å‚è€ƒ**:
- WorldMonitor: `/api/fred-data.js`, `/api/gdelt-geo.js`, `/api/earthquakes.js`, `/api/worldbank.js`
- FRED API Docs: https://fred.stlouisfed.org/docs/api/fred/series_observations.html
- GDELT API: https://blog.gdeltproject.org/gdelt-2-0-our-global-world-in-realtime/

**æˆæœ¬åˆ†æ**:
| æ•°æ®æº | è´¹ç”¨ | é™é¢ | è¯´æ˜ |
|--------|------|------|------|
| FRED | å…è´¹ | 120 requests/min | éœ€ API keyï¼Œç”³è¯·å³å¾— |
| GDELT | å…è´¹ | æ— é™åˆ¶ | æ— éœ€ key |
| USGS | å…è´¹ | æ— é™åˆ¶ | æ— éœ€ key |
| World Bank | å…è´¹ | 100 req/sec | æ— éœ€ key |
| **æ€»è®¡** | **$0** | - | å®Œå…¨å…è´¹ |

**éªŒæ”¶æ ‡å‡†**:

**ä»£ç†æ‰§è¡Œçš„ QA åœºæ™¯:**

```
åœºæ™¯: FRED å®¢æˆ·ç«¯è·å–æ•°æ®
  å·¥å…·: Bash (python)
  å‰ç½®æ¡ä»¶: FRED_API_KEY å·²é…ç½®
  æ­¥éª¤:
    1. è¿è¡Œ: python -c "from scripts.datasources.fred_client import FREDClient; c = FREDClient(); data = c.get_series('FEDFUNDS'); print(f'Got {len(data)} records')"
    2. æ–­è¨€: è¿”å›è§‚å¯Ÿåˆ—è¡¨
    3. æ–­è¨€: æ•°æ®åŒ…å« date å’Œ value å­—æ®µ
    4. è¯æ®: ä¿å­˜ç¤ºä¾‹æ•°æ®

åœºæ™¯: GDELT å®¢æˆ·ç«¯è·å–äº‹ä»¶
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. è¿è¡Œ: python -c "from scripts.datasources.gdelt_client import GDELTClient; c = GDELTClient(); events = c.query('protest', days=7); print(f'Got {len(events)} events')"
    2. æ–­è¨€: è¿”å›äº‹ä»¶åˆ—è¡¨
    3. æ–­è¨€: äº‹ä»¶æœ‰ lat/lon åæ ‡
    4. è¯æ®: ä¿å­˜ç¤ºä¾‹äº‹ä»¶

åœºæ™¯: USGS åœ°éœ‡æ•°æ®
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. è¿è¡Œ: python -c "from scripts.datasources.earthquake_client import USGSClient; c = USGSClient(); quakes = c.get_recent(); print(f'Got {len(quakes)} earthquakes')"
    2. æ–­è¨€: è¿”å›åœ°éœ‡åˆ—è¡¨
    3. æ–­è¨€: æ¯ä¸ªéœ‡çº§ >= 4.5
    4. è¯æ®: ä¿å­˜ç¤ºä¾‹æ•°æ®

åœºæ™¯: World Bank æŒ‡æ ‡
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. è¿è¡Œ: python -c "from scripts.datasources.worldbank_client import WorldBankClient; c = WorldBankClient(); data = c.get_indicator('NY.GDP.MKTP.CD', 'USA'); print(f'Got {len(data)} years')"
    2. æ–­è¨€: è¿”å›å†å² GDP æ•°æ®
    3. æ–­è¨€: æ•°æ®åŒ…å« year å’Œ value
    4. è¯æ®: ä¿å­˜ç¤ºä¾‹æ•°æ®

åœºæ™¯: å¢å¼ºä¿¡å·ç»“åˆæ•°æ®æº
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. åˆ›å»ºå…³äº "earthquake" çš„æµ‹è¯•æ–°é—»èšç±»
    2. è¿è¡Œ: python -c "from scripts.datasources.enhanced_signals import EnhancedSignalDetector; d = EnhancedSignalDetector(); signals = d.detect(cluster)"
    3. æ–­è¨€: å¦‚æœ USGS æœ‰è¿‘æœŸåœ°éœ‡ï¼Œä¿¡å·åŒ…å«ç¾éš¾è­¦æŠ¥
    4. æ–­è¨€: ä¿¡å·æœ‰ç»„åˆç½®ä¿¡åº¦è¯„åˆ†
    5. è¯æ®: ä¿å­˜ä¿¡å·è¾“å‡º
```

**æäº¤**: æ˜¯
- æ¶ˆæ¯: `feat(data): add free data sources (FRED, GDELT, USGS, World Bank)`
- æ–‡ä»¶: `scripts/datasources/` (4 ä¸ªå®¢æˆ·ç«¯æ¨¡å— + å¢å¼ºä¿¡å·)
- æäº¤å‰: æ‰€æœ‰å®¢æˆ·ç«¯å•ç‹¬æµ‹è¯•

---

### ä»»åŠ¡ 10: UI ä»ªè¡¨æ¿å¼€å‘ï¼ˆWeb Dashboardï¼‰

**åšä»€ä¹ˆ**:
å¼€å‘ä¸­æ–‡ Web ä»ªè¡¨æ¿ï¼Œå±•ç¤ºçƒ­ç‚¹åˆ†æç»“æœï¼š

1. **æŠ€æœ¯é€‰å‹**: Python Streamlit (æ¨è) æˆ– Flask
   - Streamlit ä¼˜ç‚¹ï¼šå¿«é€Ÿå¼€å‘ã€å†…ç½®ç»„ä»¶ã€è‡ªåŠ¨å“åº”å¼
   - Flask ä¼˜ç‚¹ï¼šæ›´çµæ´»ã€å¯æ‰©å±•æ€§å¼º
   - **æ¨è Streamlit** ç”¨äº MVP

2. **é¡µé¢ç»“æ„**:
   - `ğŸ  æ¦‚è§ˆé¦–é¡µ` (web/app.py:home_page)
     - ä»Šæ—¥çƒ­ç‚¹å¡ç‰‡ï¼ˆTOP 5ï¼‰
     - ä¿¡å·ç»Ÿè®¡å›¾è¡¨
     - æœ€æ–°åˆ†ææ‘˜è¦
   
   - `ğŸ”¥ çƒ­ç‚¹è¯¦æƒ…` (web/app.py:hotspots_page)
     - çƒ­ç‚¹åˆ—è¡¨ï¼ˆæŒ‰åˆ†ç±»ç­›é€‰ï¼šæ”¿æ²»/ç»æµ/å†›äº‹ï¼‰
     - çƒ­ç‚¹è¯¦æƒ…å¼¹çª—ï¼šä¸­æ–‡æ‘˜è¦ + è‹±æ–‡åŸæ–‡é“¾æ¥
     - ç›¸å…³æ–‡ç« åˆ—è¡¨
   
   - `ğŸ“Š ä¿¡å·ä¸­å¿ƒ` (web/app.py:signals_page)
     - ä¿¡å·ç±»å‹ç­›é€‰ï¼ˆé€Ÿåº¦æ¿€å¢ã€æ¥æºæ±‡èšç­‰ï¼‰
     - ä¿¡å·ç½®ä¿¡åº¦å¯è§†åŒ–
     - å†å²è¶‹åŠ¿å›¾è¡¨
   
   - `ğŸ“ˆ æ•°æ®ç»Ÿè®¡` (web/app.py:stats_page)
     - æ–‡ç« æ•°é‡è¶‹åŠ¿
     - åˆ†ç±»å æ¯”é¥¼å›¾
     - æ•°æ®æºç»Ÿè®¡

3. **æ•°æ®åº“æŸ¥è¯¢å±‚**: `web/data_api.py`
   - å°è£… Supabase æŸ¥è¯¢
   - ç¼“å­˜çƒ­ç‚¹æ•°æ®ï¼ˆå‡å°‘æ•°æ®åº“æŸ¥è¯¢ï¼‰
   - API å‡½æ•°ï¼šget_hotspots(), get_signals(), get_stats()

4. **éƒ¨ç½²é…ç½®**:
   - `web/requirements.txt` - Streamlit/flask ä¾èµ–
   - `web/README.md` - æœ¬åœ°è¿è¡Œå’Œéƒ¨ç½²è¯´æ˜
   - æ”¯æŒæœ¬åœ°è¿è¡Œï¼š`streamlit run web/app.py`
   - å¯é€‰éƒ¨ç½²ï¼šStreamlit Cloud (å…è´¹) æˆ– Railway/Heroku

**ç¦æ­¢åš**:
- ä¸è¦å®ç°ç”¨æˆ·è®¤è¯ï¼ˆå½“å‰ç‰ˆæœ¬æ— éœ€ç™»å½•ï¼‰
- ä¸è¦å®ç°å®æ—¶æ›´æ–°ï¼ˆæ‰‹åŠ¨åˆ·æ–°å³å¯ï¼‰
- ä¸è¦æ·»åŠ ç¼–è¾‘åŠŸèƒ½ï¼ˆåªè¯»å±•ç¤ºï¼‰

**æ¨èä»£ç†é…ç½®**:
- **åˆ†ç±»**: visual-engineering
- **åŸå› **: Frontend development, data visualization, UI/UX design
- **æŠ€èƒ½**: ["frontend-ui-ux"]

**å¹¶è¡ŒåŒ–**:
- **å¯å¹¶è¡Œè¿è¡Œ**: YES - Wave 5 (ä¸ Task 9 å¹¶è¡Œ)
- **é˜»å¡**: None (optional for analysis core)
- **è¢«é˜»å¡äº**: Task 1 (Database Schema)

**å‚è€ƒ**:
- Streamlit Docs: https://docs.streamlit.io/
- WorldMonitor UI pattern: Simple cards + filters + detail modals
- Visualization: Plotly or Altair for charts

**éªŒæ”¶æ ‡å‡†**:

**ä»£ç†æ‰§è¡Œçš„ QA åœºæ™¯:**

```
åœºæ™¯: Streamlit åº”ç”¨å¯åŠ¨
  å·¥å…·: Bash
  æ­¥éª¤:
    1. è¿è¡Œ: pip install -r web/requirements.txt
    2. è¿è¡Œ: timeout 5 streamlit run web/app.py || true
    3. æ–­è¨€: æ— å¯¼å…¥é”™è¯¯
    4. æ–­è¨€: è¾“å‡ºæ˜¾ç¤º "US-Monitor çƒ­ç‚¹åˆ†æ"
    5. è¯æ®: å¯åŠ¨æ—¥å¿—æˆªå›¾

åœºæ™¯: é¦–é¡µæ˜¾ç¤ºçƒ­ç‚¹å¡ç‰‡
  å·¥å…·: Playwright (playwright skill)
  å‰ç½®æ¡ä»¶: Streamlit åœ¨ localhost:8501 è¿è¡Œ
  æ­¥éª¤:
    1. å¯¼èˆªåˆ°: http://localhost:8501
    2. ç­‰å¾…: "US-Monitor çƒ­ç‚¹åˆ†æ" å¯è§ï¼ˆè¶…æ—¶: 10sï¼‰
    3. æ–­è¨€: é¡µé¢åŒ…å« "ä»Šæ—¥çƒ­ç‚¹" éƒ¨åˆ†
    4. æ–­è¨€: è‡³å°‘æ˜¾ç¤º 1 ä¸ªçƒ­ç‚¹å¡ç‰‡ï¼ˆå¦‚æœæœ‰æ•°æ®ï¼‰
    5. æˆªå›¾: .sisyphus/evidence/task-10-homepage.png

åœºæ™¯: çƒ­ç‚¹è¯¦æƒ…é¡µæ˜¾ç¤ºä¸­æ–‡æ‘˜è¦
  å·¥å…·: Playwright (playwright skill)
  æ­¥éª¤:
    1. å¯¼èˆªåˆ°: http://localhost:8501
    2. ç‚¹å‡»: "çƒ­ç‚¹è¯¦æƒ…" æ ‡ç­¾
    3. ç­‰å¾…: è¡¨æ ¼æˆ–åˆ—è¡¨å¯è§
    4. æ–­è¨€: æ˜¾ç¤º "ä¸­æ–‡æ‘˜è¦" åˆ—
    5. æ–­è¨€: æ˜¾ç¤º "è‹±æ–‡åŸæ–‡" é“¾æ¥
    6. æˆªå›¾: .sisyphus/evidence/task-10-hotspots.png

åœºæ™¯: ä¿¡å·ä¸­å¿ƒæ˜¾ç¤ºå›¾è¡¨
  å·¥å…·: Playwright (playwright skill)
  æ­¥éª¤:
    1. å¯¼èˆªåˆ°: http://localhost:8501
    2. ç‚¹å‡»: "ä¿¡å·ä¸­å¿ƒ" æ ‡ç­¾
    3. ç­‰å¾…: å›¾è¡¨å¯è§
    4. æ–­è¨€: æ˜¾ç¤ºä¿¡å·ç±»å‹ç­›é€‰å™¨
    5. æ–­è¨€: æ˜¾ç¤ºç½®ä¿¡åº¦å¯è§†åŒ–
    6. æˆªå›¾: .sisyphus/evidence/task-10-signals.png

åœºæ™¯: æ•°æ®ç»Ÿè®¡é¡µæ˜¾ç¤ºå›¾è¡¨
  å·¥å…·: Playwright (playwright skill)
  æ­¥éª¤:
    1. å¯¼èˆªåˆ°: http://localhost:8501
    2. ç‚¹å‡»: "æ•°æ®ç»Ÿè®¡" æ ‡ç­¾
    3. ç­‰å¾…: å›¾è¡¨å¯è§
    4. æ–­è¨€: æ˜¾ç¤ºæ–‡ç« æ•°é‡è¶‹åŠ¿å›¾
    5. æ–­è¨€: æ˜¾ç¤ºåˆ†ç±»é¥¼å›¾
    6. æˆªå›¾: .sisyphus/evidence/task-10-stats.png

åœºæ™¯: ç§»åŠ¨ç«¯å“åº”å¼
  å·¥å…·: Playwright (playwright skill)
  æ­¥éª¤:
    1. è®¾ç½®è§†å£: 375x812 (iPhone X)
    2. å¯¼èˆªåˆ°: http://localhost:8501
    3. æ–­è¨€: å¸ƒå±€é€‚é…ç§»åŠ¨ç«¯
    4. æ–­è¨€: æ‰€æœ‰å†…å®¹å¯è§ï¼Œæ— æ°´å¹³æ»šåŠ¨
    5. æˆªå›¾: .sisyphus/evidence/task-10-mobile.png
```

**æäº¤**: æ˜¯
- æ¶ˆæ¯: `feat(ui): add Streamlit dashboard with Chinese interface`
- æ–‡ä»¶: `web/app.py`, `web/data_api.py`, `web/requirements.txt`, `web/README.md`
- æäº¤å‰: åº”ç”¨å¯åŠ¨æ— é”™è¯¯

---

### ä»»åŠ¡ 11: å¢å¼ºåˆ†æå™¨ï¼ˆEnhanced Analyzerï¼‰

**åšä»€ä¹ˆ**:
æ•´åˆå…è´¹æ•°æ®æºåˆ°ä¸»åˆ†æå™¨ï¼Œç”Ÿæˆå¢å¼ºå‹ä¿¡å·ï¼š

1. **ä¿®æ”¹ `scripts/analyzer.py`**:
   - åœ¨èšç±»åè°ƒç”¨å…è´¹æ•°æ®æºå®¢æˆ·ç«¯
   - æ ¹æ®æ•°æ®æºç»“æœå¢å¼ºä¿¡å·æ£€æµ‹
   - ç¤ºä¾‹å¢å¼ºé€»è¾‘ï¼š
     - å¦‚æœæ–°é—»èšç±»åŒ…å« "Fed", "interest rate" + FRED æ˜¾ç¤ºåˆ©ç‡å˜åŒ– â†’ economic_indicator_alert
     - å¦‚æœæ–°é—»èšç±»åŒ…å« "earthquake" + USGS æ˜¾ç¤ºè¿‘æœŸåœ°éœ‡ â†’ natural_disaster_signal

2. **ä¸­æ–‡ LLM æç¤ºè¯** (config/analysis_config.py):
```python
LLM_PROMPTS = {
    "cluster_summary": """
    è¯·å°†ä»¥ä¸‹è‹±æ–‡æ–°é—»èšç±»æ€»ç»“ä¸ºä¸­æ–‡æ‘˜è¦ã€‚
    
    èšç±»åŒ…å« {article_count} ç¯‡æ–‡ç« ï¼Œæ¥æºï¼š{sources}
    ä¸»è¦æ ‡é¢˜ï¼š{primary_title}
    
    è¦æ±‚ï¼š
    1. ç”¨ä¸­æ–‡æ’°å†™ï¼Œ200-300 å­—
    2. æ¦‚æ‹¬æ ¸å¿ƒäº‹ä»¶å’Œè¦ç‚¹
    3. æŒ‡å‡ºæ¶‰åŠçš„å…³é”®å®ä½“ï¼ˆäººç‰©ã€ç»„ç»‡ã€åœ°ç‚¹ï¼‰
    4. åˆ†æå¯èƒ½çš„å½±å“å’Œè¶‹åŠ¿
    5. ä¿æŒå®¢è§‚ä¸­ç«‹çš„è¯­æ°”
    
    è¾“å‡ºæ ¼å¼ï¼š
    {
      "summary": "ä¸­æ–‡æ‘˜è¦",
      "key_entities": ["å®ä½“1", "å®ä½“2"],
      "impact": "å½±å“åˆ†æ",
      "trend": "è¶‹åŠ¿åˆ¤æ–­"
    }
    """,
    
    "signal_rationale": """
    è¯·ä¸ºæ£€æµ‹åˆ°çš„ä¿¡å·æä¾›ä¸­æ–‡è§£é‡Šã€‚
    
    ä¿¡å·ç±»å‹ï¼š{signal_type}
    ç½®ä¿¡åº¦ï¼š{confidence}
    ç›¸å…³æ–‡ç« æ•°ï¼š{article_count}
    
    è¦æ±‚ï¼š
    1. è§£é‡Šä¸ºä»€ä¹ˆè¿™ä¸ªä¿¡å·é‡è¦
    2. æä¾›å¯æ‰§è¡Œçš„å»ºè®®
    3. è¯´æ˜ç½®ä¿¡åº¦ä¾æ®
    4. ä¿æŒä¸­æ–‡è¾“å‡º
    """
}
```

3. **æ•°æ®æºå…³è”**:
   - ä¸ºæ¯ä¸ªèšç±»æ·»åŠ  `data_sources` å­—æ®µï¼ˆJSONBï¼‰
   - å­˜å‚¨å…³è”çš„ FRED æŒ‡æ ‡ã€GDELT äº‹ä»¶ã€åœ°éœ‡æ•°æ®ç­‰
   - åœ¨ UI ä¸­å±•ç¤ºæ•°æ®æºå…³è”

4. **å¢å¼ºä¿¡å·å­˜å‚¨**:
   - æ–°å¢ä¿¡å·ç±»å‹åˆ° `analysis_signals` è¡¨
   - æ·»åŠ  `data_source` å­—æ®µæ ‡è¯†ä¿¡å·æ¥æº

**ç¦æ­¢åš**:
- ä¸è¦é˜»å¡åˆ†ææµç¨‹ç­‰å¾… APIï¼ˆä½¿ç”¨ asyncio å¹¶å‘ï¼‰
- ä¸è¦å­˜å‚¨åŸå§‹ API å“åº”ï¼ˆåªå­˜å‚¨å¤„ç†åçš„å…³é”®æ•°æ®ï¼‰
- ä¸è¦åœ¨æ²¡æœ‰æ–°é—»å…³è”æ—¶ç”Ÿæˆä¿¡å·

**æ¨èä»£ç†é…ç½®**:
- **åˆ†ç±»**: ultrabrain
- **åŸå› **: Complex integration, async orchestration, data correlation
- **æŠ€èƒ½**: None needed

**å¹¶è¡ŒåŒ–**:
- **å¯å¹¶è¡Œè¿è¡Œ**: NO - Wave 6 (Final Integration)
- **é˜»å¡**: Task 12 (Final Testing)
- **è¢«é˜»å¡äº**: Tasks 6, 9, 10

**å‚è€ƒ**:
- Task 6: Original analyzer structure
- Task 9: Data source clients
- WorldMonitor: Enhanced signal patterns

**éªŒæ”¶æ ‡å‡†**:

**ä»£ç†æ‰§è¡Œçš„ QA åœºæ™¯:**

```
åœºæ™¯: Analyzer uses Chinese prompts
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. Check config: python -c "from config.analysis_config import LLM_PROMPTS; print('cluster_summary' in LLM_PROMPTS)"
    2. Assert: LLM_PROMPTS contains Chinese prompts
    3. Verify: Prompts are in Chinese with JSON format instructions
    4. Evidence: Save prompt content

åœºæ™¯: Enhanced analyzer runs with data sources
  å·¥å…·: Bash (python)
  å‰ç½®æ¡ä»¶: All data source clients working
  æ­¥éª¤:
    1. Run: python scripts/analyzer.py --limit 10 --enhanced
    2. Assert: Log shows "Fetching FRED data..."
    3. Assert: Log shows "Fetching GDELT events..."
    4. Assert: Completes without errors
    5. Evidence: Full log output

åœºæ™¯: Chinese summaries stored
  å·¥å…·: Bash (psql)
  æ­¥éª¤:
    1. Query: SELECT summary FROM analysis_clusters ORDER BY created_at DESC LIMIT 3
    2. Assert: Summaries contain Chinese characters
    3. Assert: Length is 200-500 Chinese characters
    4. Evidence: Save sample summaries

åœºæ™¯: English source links preserved
  å·¥å…·: Bash (psql)
  æ­¥éª¤:
    1. Query: SELECT primary_title, primary_link FROM analysis_clusters LIMIT 1
    2. Assert: primary_title is in English
    3. Assert: primary_link is valid URL
    4. Evidence: Screenshot of query results

åœºæ™¯: Enhanced signals detected
  å·¥å…·: Bash (psql)
  æ­¥éª¤:
    1. Query: SELECT signal_type, data_source FROM analysis_signals WHERE data_source IS NOT NULL
    2. Assert: Shows enhanced signals (if conditions met)
    3. Assert: data_source field populated
    4. Evidence: Save query results

åœºæ™¯: Data sources linked to clusters
  å·¥å…·: Bash (psql)
  æ­¥éª¤:
    1. Query: SELECT data_sources FROM analysis_clusters WHERE data_sources IS NOT NULL LIMIT 1
    2. Assert: data_sources JSON contains FRED/GDELT/USGS/WorldBank keys
    3. Assert: Structure matches expected format
    4. Evidence: Save sample JSON
```

**æäº¤**: æ˜¯
- æ¶ˆæ¯: `feat(analyzer): integrate data sources and Chinese LLM prompts`
- æ–‡ä»¶: `scripts/analyzer.py` (enhanced), `config/analysis_config.py` (Chinese prompts)
- æäº¤å‰: Full test run with --enhanced flag

---

### ä»»åŠ¡ 12: æœ€ç»ˆç«¯åˆ°ç«¯æµ‹è¯•ï¼ˆFinal E2E Testingï¼‰

**åšä»€ä¹ˆ**:
å®Œæ•´ç³»ç»Ÿç«¯åˆ°ç«¯æµ‹è¯•ï¼ŒåŒ…æ‹¬ï¼š
1. çˆ¬è™« â†’ åˆ†æå™¨ â†’ UI å®Œæ•´æµç¨‹
2. ä¸­æ–‡è¾“å‡ºè´¨é‡éªŒè¯
3. æ•°æ®æºé›†æˆéªŒè¯
4. UI åŠŸèƒ½éªŒè¯
5. æ€§èƒ½æµ‹è¯•ï¼ˆ500 æ–‡ç«  <30 åˆ†é’Ÿï¼‰

**Additional Test Scenarios**:

```
åœºæ™¯: å®Œæ•´æµç¨‹ä¸­æ–‡è¾“å‡º
  å·¥å…·: Playwright + Bash
  æ­¥éª¤:
    1. è¿è¡Œçˆ¬è™«è·å–æ–°æ–‡ç« 
    2. è¿è¡Œåˆ†æå™¨ï¼ˆå¸¦æ•°æ®æºå¢å¼ºï¼‰
    3. æ‰“å¼€ UI ä»ªè¡¨æ¿
    4. Assert: æ‰€æœ‰æ‘˜è¦åœ¨ UI ä¸­æ˜¾ç¤ºä¸ºä¸­æ–‡
    5. Assert: ç‚¹å‡»"è‹±æ–‡åŸæ–‡"é“¾æ¥å¯è·³è½¬
    6. Evidence: å½•å±æˆ–æˆªå›¾åºåˆ—

åœºæ™¯: æ•°æ®æºä¿¡å·éªŒè¯
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. ç­‰å¾…çœŸå®ç»æµæ•°æ®å‘å¸ƒï¼ˆæˆ–æ¨¡æ‹Ÿï¼‰
    2. è¿è¡Œåˆ†æå™¨
    3. æ£€æŸ¥ï¼šanalysis_signals è¡¨åŒ…å« economic_indicator_alert
    4. Assert: ä¿¡å·ç½®ä¿¡åº¦ > 0.6
    5. Evidence: æ•°æ®åº“æŸ¥è¯¢ç»“æœ

åœºæ™¯: ç³»ç»Ÿæ€§èƒ½
  å·¥å…·: Bash (python)
  æ­¥éª¤:
    1. æ’å…¥ 500 ç¯‡æµ‹è¯•æ–‡ç« 
    2. è®¡æ—¶ï¼štime python scripts/analyzer.py
    3. Assert: æ€»æ—¶é—´ < 30 åˆ†é’Ÿ
    4. Assert: LLM è°ƒç”¨æ¬¡æ•° < 200
    5. Evidence: æ—¶é—´æŠ¥å‘Š
```

**æäº¤**: æ˜¯
- æ¶ˆæ¯: `test(e2e): complete system validation with Chinese output and data sources`
- æ–‡ä»¶: `tests/test_complete_system.py`, `tests/final_report.md`
- æäº¤å‰: All tests pass

---

## Updated Execution Strategy

### New Parallel Execution Waves

```
Wave 1 (Foundation):
â”œâ”€â”€ Task 1: Database Schema
â”œâ”€â”€ Task 2: LLM Client Module
â””â”€â”€ Task 3: Configuration & Constants

Wave 2 (Core Logic):
â”œâ”€â”€ Task 4: Clustering Engine
â””â”€â”€ Task 5: Signal Detection

Wave 3 (Integration):
â”œâ”€â”€ Task 6: Main Analyzer Pipeline
â””â”€â”€ Task 7: GitHub Actions Workflow

Wave 4 (Validation):
â””â”€â”€ Task 8: End-to-End Testing

Wave 5 (Enhancement - Can Start After Wave 1):
â”œâ”€â”€ Task 9: Free Data Sources
â””â”€â”€ Task 10: UI Dashboard

Wave 6 (Final Integration):
â”œâ”€â”€ Task 11: Enhanced Analyzer
â””â”€â”€ Task 12: Final E2E Testing

å…³é”®è·¯å¾„: Task 1 â†’ Task 4 â†’ Task 6 â†’ Task 11 â†’ Task 12
UI è·¯å¾„: Task 1 â†’ Task 10 (independent, can be used separately)
```

---

## Commit Strategy

| After Task | Message | Files | Verification |
|------------|---------|-------|--------------|
| 1 | `feat(db): add analysis schema for hotspot detection` | `sql/analysis_schema.sql` | Schema applies without errors |
| 2 | `feat(llm): add Alibaba Qwen3-Plus client with retry and caching` | `scripts/llm_client.py`, `.env.example` | Client imports successfully |
| 3 | `feat(config): add analysis configuration with thresholds and prompts` | `config/analysis_config.py` | Config loads correctly |
| 4 | `feat(clustering): implement Jaccard similarity clustering with inverted index` | `scripts/clustering.py` | Clustering tests pass |
| 5 | `feat(signals): implement velocity, convergence, triangulation detection` | `scripts/signal_detector.py` | Signal tests pass |
| 6 | `feat(analyzer): add main analysis pipeline with clustering and LLM` | `scripts/analyzer.py` | E2E test with --limit 10 |
| 7 | `ci(actions): add analyzer workflow for automated hotspot detection` | `.github/workflows/analyzer.yml` | YAML valid, workflow runs |
| 8 | `test(e2e): add end-to-end validation and test report` | `tests/test_analyzer_e2e.py`, `tests/report.md` | All tests pass |
| 9 | `feat(data): add free data sources (FRED, GDELT, USGS, World Bank)` | `scripts/datasources/` | All APIs tested |
| 10 | `feat(ui): add Streamlit dashboard with Chinese interface` | `web/` | UI loads and displays data |
| 11 | `feat(analyzer): integrate data sources and Chinese LLM prompts` | `scripts/analyzer.py`, `config/` | Enhanced analysis works |
| 12 | `test(e2e): complete system validation with Chinese output and data sources` | `tests/test_complete_system.py` | All tests pass |

---

## Success Criteria

### Verification Commands

```bash
# Test database schema
psql $SUPABASE_URL -f sql/analysis_schema.sql && echo "Schema OK"

# Test imports
python -c "from scripts.analyzer import main; print('Imports OK')"

# Run with limit
python scripts/analyzer.py --limit 10 && echo "Analyzer OK"

# Check results
psql $SUPABASE_URL -c "SELECT COUNT(*) FROM analysis_clusters" && echo "Data OK"
```

### Final Checklist
- [ ] All 12 tasks complete
- [ ] Database schema created and applied
- [ ] LLM client working with retry/caching
- [ ] Clustering produces 50-200 clusters for typical dataset
- [ ] Signal detection finds meaningful patterns
- [ ] GitHub Actions workflow runs automatically
- [ ] Analysis completes in <30 minutes
- [ ] Only unanalyzed articles processed (incremental)
- [ ] Error handling graceful (no crashes on bad data)
- [ ] **ä¸­æ–‡æ‘˜è¦æ­£å¸¸è¾“å‡º** (Chinese summaries displayed)
- [ ] **è‹±æ–‡åŸæ–‡é“¾æ¥å¯ç‚¹å‡»** (English source links work)
- [ ] **å…è´¹æ•°æ®æºé›†æˆ** (FRED, GDELT, USGS, World Bank connected)
- [ ] **UIä»ªè¡¨æ¿å¯è®¿é—®** (Web dashboard accessible)
- [ ] **ç§»åŠ¨ç«¯å“åº”å¼æ­£å¸¸** (Mobile responsive)
- [ ] All QA scenarios pass with evidence

---

## Appendix: Free Data Sources Integration

### Available Free/Low-Cost Data Sources (from WorldMonitor)

#### 1. FRED (Federal Reserve Economic Data)
- **URL**: https://fred.stlouisfed.org/
- **Cost**: å…è´¹ï¼ˆéœ€ API keyï¼‰
- **API Key**: https://fred.stlouisfed.org/docs/api/api_key.html
- **Rate Limit**: 120 requests/minute
- **Use Cases**:
  - è”é‚¦åŸºé‡‘åˆ©ç‡å˜åŒ– â†’ è´§å¸æ”¿ç­–ä¿¡å·
  - CPI/PPI æ•°æ® â†’ é€šèƒ€ä¿¡å·
  - å¤±ä¸šç‡ â†’ ç»æµå¥åº·åº¦
  - GDP å¢é•¿ â†’ å®è§‚è¶‹åŠ¿
- **Key Series IDs**:
  - `FEDFUNDS` - è”é‚¦åŸºé‡‘åˆ©ç‡
  - `CPIAUCSL` - CPI
  - `UNRATE` - å¤±ä¸šç‡
  - `GDP` - GDP

#### 2. GDELT (Global Database of Events, Language, and Tone)
- **URL**: https://www.gdeltproject.org/
- **Cost**: å®Œå…¨å…è´¹
- **API Key**: ä¸éœ€è¦
- **Rate Limit**: æ— é™åˆ¶ï¼ˆåˆç†é¢‘ç‡ï¼‰
- **Use Cases**:
  - å…¨çƒæŠ—è®®æ´»åŠ¨åœ°ç†åˆ†å¸ƒ
  - å†²çªäº‹ä»¶å¼ºåº¦å’Œä½ç½®
  - æ–°é—»æƒ…ç»ªåˆ†æ
- **Endpoints**:
  - Geo API: `https://api.gdeltproject.org/api/v2/geo/geo`
  - Document API: `https://api.gdeltproject.org/api/v2/doc/doc`

#### 3. USGS Earthquakes
- **URL**: https://earthquake.usgs.gov/
- **Cost**: å®Œå…¨å…è´¹
- **API Key**: ä¸éœ€è¦
- **Rate Limit**: æ— é™åˆ¶
- **Use Cases**:
  - 4.5 çº§ä»¥ä¸Šåœ°éœ‡å®æ—¶ç›‘æµ‹
  - è‡ªç„¶ç¾å®³æ–°é—»éªŒè¯
  - äººé“ä¸»ä¹‰å±æœºé¢„è­¦
- **Endpoint**: `https://earthquake.usgs.gov/earthquakes/feed/v1.0/summary/4.5_day.geojson`

#### 4. World Bank Open Data
- **URL**: https://data.worldbank.org/
- **Cost**: å®Œå…¨å…è´¹
- **API Key**: ä¸éœ€è¦
- **Rate Limit**: 100 requests/second
- **Use Cases**:
  - å›½å®¶ GDP æ•°æ®
  - ç ”å‘æŠ•å…¥æŒ‡æ ‡
  - äº’è”ç½‘æ™®åŠç‡
  - æ•™è‚²æ”¯å‡º
- **Key Indicators**:
  - `NY.GDP.MKTP.CD` - GDP (current US$)
  - `NY.GDP.MKTP.KD.ZG` - GDP growth
  - `GB.XPD.RSDV.GD.ZS` - R&D expenditure
  - `IT.NET.USER.ZS` - Internet users

#### 5. Hacker News (Bonus)
- **URL**: https://news.ycombinator.com/
- **Cost**: å®Œå…¨å…è´¹
- **API**: https://github.com/HackerNews/API
- **Use Cases**:
  - ç§‘æŠ€è¶‹åŠ¿ç›‘æµ‹
  - åˆ›ä¸šç”Ÿæ€ä¿¡å·
  - æŠ€æœ¯è¯é¢˜çƒ­åº¦

### Signal Enhancement Strategy

```python
# Example: Enhanced Signal Detection
class EnhancedSignalDetector:
    def detect_economic_signals(self, cluster, fred_data):
        """Detect economic indicator alerts"""
        economic_keywords = ['Fed', 'interest rate', 'inflation', 'CPI', 'GDP']
        
        if any(kw in cluster['primary_title'] for kw in economic_keywords):
            # Check FRED for recent changes
            recent_changes = self.check_fred_changes(fred_data)
            if recent_changes:
                return {
                    'type': 'economic_indicator_alert',
                    'confidence': 0.8,
                    'data_source': 'FRED',
                    'related_indicators': recent_changes
                }
    
    def detect_disaster_signals(self, cluster, usgs_data):
        """Detect natural disaster signals"""
        disaster_keywords = ['earthquake', 'tsunami', 'volcano', 'disaster']
        
        if any(kw in cluster['primary_title'].lower() for kw in disaster_keywords):
            # Check USGS for recent earthquakes
            recent_quakes = self.check_usgs_recent(usgs_data)
            if recent_quakes:
                return {
                    'type': 'natural_disaster_signal',
                    'confidence': 0.85,
                    'data_source': 'USGS',
                    'magnitude': recent_quakes[0]['magnitude'],
                    'location': recent_quakes[0]['place']
                }
    
    def detect_geopolitical_intensity(self, cluster, gdelt_data):
        """Detect geopolitical event intensity"""
        # Extract location from cluster
        location = self.extract_location(cluster)
        
        # Query GDELT for events near that location
        nearby_events = self.query_gdelt_nearby(gdelt_data, location)
        
        if len(nearby_events) > 5:
            return {
                'type': 'geopolitical_intensity',
                'confidence': min(0.9, 0.5 + len(nearby_events) * 0.05),
                'data_source': 'GDELT',
                'event_count': len(nearby_events),
                'avg_tone': self.calculate_avg_tone(nearby_events)
            }
```

### Cost Summary

| Data Source | Monthly Cost | Monthly Quota | Setup Effort |
|-------------|--------------|---------------|--------------|
| FRED | $0 | 120 req/min | Low (API key) |
| GDELT | $0 | Unlimited | None |
| USGS | $0 | Unlimited | None |
| World Bank | $0 | 100 req/sec | None |
| **Total** | **$0** | - | **Low** |

### Implementation Notes

1. **Caching Strategy**: Cache API responses for 1-6 hours to reduce calls
2. **Async Fetching**: Use `asyncio.gather()` to fetch all data sources concurrently
3. **Graceful Degradation**: If one API fails, continue with others
4. **Rate Limiting**: Implement client-side rate limiting for FRED (120/min)
5. **Data Retention**: Store only processed/aggregated data, not raw API responses

---

## Appendix: Key WorldMonitor Patterns

### Jaccard Clustering Algorithm
```python
# From analysis-core.ts:154-280
def cluster_news(items):
    # 1. Tokenize all titles
    # 2. Build inverted index (token -> article indices)
    # 3. For each article, find candidates sharing tokens
    # 4. Calculate Jaccard similarity with candidates
    # 5. Group if similarity >= 0.5
    # 6. Sort clusters by tier and recency
    # 7. Aggregate threats and geo locations
```

### Signal Detection Pattern
```python
# From analysis-core.ts:302-434
def detect_convergence(clusters):
    # 1. Filter clusters with 3+ sources
    # 2. Check source types (wire, gov, intel, mainstream)
    # 3. If 3+ different types in 1 hour window
    # 4. Generate signal with confidence 0.6-0.95
    # 5. Deduplicate via generateDedupeKey
```

### Escalation Scoring
```python
# From hotspot-escalation.ts:174-217
COMPONENT_WEIGHTS = {
    'news': 0.35,
    'cii': 0.25,
    'geo': 0.25,
    'military': 0.15
}
# Calculate component scores (0-100)
# Weighted sum â†’ raw score â†’ 1-5 scale
# Blend with static baseline (30% static, 70% dynamic)
```

---

## Notes for Implementer

1. **Database Performance**: With 1000+ articles, clustering is O(nÂ²). Use inverted index optimization from worldmonitor.

2. **LLM Costs**: At ~$0.002 per 1K tokens, 200 calls Ã— 4K tokens = $1.60 per run. Well within reasonable budget.

3. **Signal Cooldown**: Implement 2-hour cooldown to prevent signal spam (same as worldmonitor).

4. **Testing Strategy**: Start with `--limit 10`, then 50, then full dataset. Monitor performance.

5. **Debugging**: Add verbose logging option. Store intermediate cluster data for inspection.

6. **Schema Evolution**: Add `version` column to analysis tables for future migrations.

7. **Fallback Strategy**: If LLM API fails, fall back to keyword-based summarization (title + snippet extraction).

---

*Plan generated by Prometheus (Plan Builder)*  
*Based on worldmonitor architecture analysis and Metis gap review*
