#!/usr/bin/env python3
"""
RSSæºå¯ç”¨æ€§éªŒè¯å·¥å…·
éªŒè¯æ•°æ®åº“ä¸­å“ªäº›RSSæºæ˜¯å¯è®¿é—®çš„
æ”¯æŒæœ¬åœ°å’ŒGitHub Actionsè¿è¡Œ
"""

import asyncio
import aiohttp
import feedparser
import json
import os
import sys
from datetime import datetime
from typing import List, Dict, Optional
from supabase import create_client

# é…ç½®
SUPABASE_URL = os.getenv("SUPABASE_URL", "https://lwigqxyfxevldfjdeokp.supabase.co")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")

# æµ‹è¯•é…ç½®
TEST_TIMEOUT = 20  # è¯·æ±‚è¶…æ—¶æ—¶é—´
MAX_SOURCES = None  # None=æµ‹è¯•å…¨éƒ¨ï¼Œè®¾ç½®ä¸ºæ•°å­—é™åˆ¶æµ‹è¯•æ•°é‡


class RSSValidator:
    def __init__(self):
        if not SUPABASE_KEY:
            print("âŒ é”™è¯¯: æœªè®¾ç½® SUPABASE_KEY ç¯å¢ƒå˜é‡")
            sys.exit(1)

        self.supabase = create_client(SUPABASE_URL, SUPABASE_KEY)
        self.results = []
        self.stats = {"total": 0, "working": 0, "failed": 0, "by_category": {}}

    async def test_source(self, source: Dict, session: aiohttp.ClientSession) -> Dict:
        """æµ‹è¯•å•ä¸ªRSSæº"""
        result = {
            "id": source["id"],
            "name": source["name"],
            "category": source["category"],
            "rss_url": source["rss_url"],
            "status": "unknown",
            "http_status": None,
            "articles_count": 0,
            "error": None,
            "response_time": 0,
        }

        start_time = datetime.now()

        try:
            async with session.get(
                source["rss_url"],
                headers={"User-Agent": "Mozilla/5.0 (compatible; RSSValidator/1.0)"},
                timeout=aiohttp.ClientTimeout(total=TEST_TIMEOUT),
            ) as resp:
                result["http_status"] = resp.status
                result["response_time"] = (datetime.now() - start_time).total_seconds()

                if resp.status == 200:
                    content = await resp.text()
                    feed = feedparser.parse(content)

                    if feed.entries:
                        result["status"] = "working"
                        result["articles_count"] = len(feed.entries)
                        # è®°å½•æœ€æ–°æ–‡ç« æ ‡é¢˜
                        result["latest_article"] = feed.entries[0].get("title", "N/A")[
                            :60
                        ]
                    else:
                        result["status"] = "empty"
                        result["error"] = "RSS parsed but no entries found"
                else:
                    result["status"] = "error"
                    result["error"] = f"HTTP {resp.status}"

        except asyncio.TimeoutError:
            result["status"] = "timeout"
            result["error"] = f"Timeout after {TEST_TIMEOUT}s"
        except Exception as e:
            result["status"] = "error"
            result["error"] = str(e)[:100]

        return result

    async def validate_all(self):
        """éªŒè¯æ‰€æœ‰RSSæº"""
        print("=" * 70)
        print("ğŸ§ª RSSæºå¯ç”¨æ€§éªŒè¯")
        print("=" * 70)
        print(f"â±ï¸  è¶…æ—¶è®¾ç½®: {TEST_TIMEOUT}ç§’")
        print(f"ğŸ—„ï¸  æ•°æ®åº“: {SUPABASE_URL}")
        print()

        # è·å–æ‰€æœ‰æº
        print("ğŸ“Š æ­£åœ¨è·å–RSSæºåˆ—è¡¨...")
        sources = (
            self.supabase.table("rss_sources")
            .select("*")
            .eq("status", "active")
            .execute()
            .data
        )

        if MAX_SOURCES:
            sources = sources[:MAX_SOURCES]

        self.stats["total"] = len(sources)
        print(f"âœ… è·å–åˆ° {len(sources)} ä¸ªRSSæº\n")

        # å¹¶å‘æµ‹è¯•
        print("ğŸš€ å¼€å§‹æµ‹è¯•...\n")
        timeout = aiohttp.ClientTimeout(total=TEST_TIMEOUT)

        async with aiohttp.ClientSession(timeout=timeout) as session:
            # ä½¿ç”¨ semaphore é™åˆ¶å¹¶å‘
            semaphore = asyncio.Semaphore(10)

            async def test_with_limit(source):
                async with semaphore:
                    result = await self.test_source(source, session)
                    # å®æ—¶æ‰“å°ç»“æœ
                    status_icon = "âœ…" if result["status"] == "working" else "âš ï¸ "
                    print(
                        f"{status_icon} {result['name'][:40]:<40} | {result['status']:<10} | {result.get('articles_count', 0):>3} articles"
                    )
                    return result

            tasks = [test_with_limit(s) for s in sources]
            self.results = await asyncio.gather(*tasks)

        # ç»Ÿè®¡
        self._calculate_stats()

        # ç”ŸæˆæŠ¥å‘Š
        self._print_report()
        self._save_report()
        self._update_database()

    def _calculate_stats(self):
        """è®¡ç®—ç»Ÿè®¡ä¿¡æ¯"""
        for result in self.results:
            if result["status"] == "working":
                self.stats["working"] += 1
            else:
                self.stats["failed"] += 1

            # æŒ‰åˆ†ç±»ç»Ÿè®¡
            cat = result["category"]
            if cat not in self.stats["by_category"]:
                self.stats["by_category"][cat] = {"total": 0, "working": 0}
            self.stats["by_category"][cat]["total"] += 1
            if result["status"] == "working":
                self.stats["by_category"][cat]["working"] += 1

    def _print_report(self):
        """æ‰“å°æŠ¥å‘Š"""
        print("\n" + "=" * 70)
        print("ğŸ“Š éªŒè¯æŠ¥å‘Š")
        print("=" * 70)

        # æ€»ä½“ç»Ÿè®¡
        print(f"\næ€»ä½“ç»Ÿè®¡:")
        print(f"  æ€»æºæ•°: {self.stats['total']}")
        print(
            f"  âœ… å¯ç”¨: {self.stats['working']} ({self.stats['working'] / self.stats['total'] * 100:.1f}%)"
        )
        print(
            f"  âŒ ä¸å¯ç”¨: {self.stats['failed']} ({self.stats['failed'] / self.stats['total'] * 100:.1f}%)"
        )

        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        print(f"\næŒ‰åˆ†ç±»ç»Ÿè®¡:")
        for cat, data in self.stats["by_category"].items():
            rate = data["working"] / data["total"] * 100 if data["total"] > 0 else 0
            print(
                f"  {cat:<12}: {data['working']:>3}/{data['total']:<3} ({rate:>5.1f}%)"
            )

        # ä¸å¯ç”¨çš„æº
        failed_sources = [r for r in self.results if r["status"] != "working"]
        if failed_sources:
            print(f"\nâŒ ä¸å¯ç”¨çš„æº ({len(failed_sources)}ä¸ª):")
            for r in failed_sources[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(
                    f"  - {r['name'][:40]:<40} | {r['status']:<10} | {r['error'][:40]}"
                )
            if len(failed_sources) > 10:
                print(f"  ... è¿˜æœ‰ {len(failed_sources) - 10} ä¸ª")

        # å¯ç”¨çš„æºç¤ºä¾‹
        working_sources = [r for r in self.results if r["status"] == "working"]
        if working_sources:
            print(f"\nâœ… å¯ç”¨çš„æºç¤ºä¾‹ ({len(working_sources)}ä¸ªä¸­çš„å‰5ä¸ª):")
            for r in working_sources[:5]:
                print(f"  - {r['name'][:40]:<40} | {r['articles_count']:>3} articles")
                print(f"    Latest: {r.get('latest_article', 'N/A')}")

        print("\n" + "=" * 70)

    def _save_report(self):
        """ä¿å­˜è¯¦ç»†æŠ¥å‘Šåˆ°JSON"""
        report = {
            "timestamp": datetime.now().isoformat(),
            "stats": self.stats,
            "results": self.results,
        }

        filename = (
            f"rss_validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        )
        with open(filename, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {filename}")

        # åŒæ—¶ä¿å­˜CSVæ ¼å¼
        csv_filename = (
            f"rss_validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
        )
        with open(csv_filename, "w", encoding="utf-8") as f:
            f.write(
                "id,name,category,rss_url,status,http_status,articles_count,error\n"
            )
            for r in self.results:
                f.write(
                    f'{r["id"]},{r["name"]},{r["category"]},{r["rss_url"]},{r["status"]},{r["http_status"]},{r["articles_count"]},"{r["error"] or ""}"\n'
                )

        print(f"ğŸ’¾ CSVæŠ¥å‘Šå·²ä¿å­˜: {csv_filename}")

    def _update_database(self):
        """æ›´æ–°æ•°æ®åº“ä¸­çš„æºçŠ¶æ€"""
        print("\nğŸ”„ æ›´æ–°æ•°æ®åº“çŠ¶æ€...")

        updated = 0
        for result in self.results:
            try:
                status = "active" if result["status"] == "working" else "error"
                self.supabase.table("rss_sources").update(
                    {"status": status, "last_fetch": datetime.now().isoformat()}
                ).eq("id", result["id"]).execute()
                updated += 1
            except Exception as e:
                print(f"  âš ï¸  æ›´æ–°æº {result['id']} å¤±è´¥: {e}")

        print(f"âœ… å·²æ›´æ–° {updated} ä¸ªæºçš„çŠ¶æ€")


async def main():
    validator = RSSValidator()
    await validator.validate_all()

    # å¦‚æœæœ‰å¯ç”¨æºï¼Œè¿”å›æˆåŠŸ
    if validator.stats["working"] > 0:
        print(f"\nâœ… éªŒè¯å®Œæˆï¼å‘ç° {validator.stats['working']} ä¸ªå¯ç”¨æº")
        return 0
    else:
        print(f"\nâš ï¸  è­¦å‘Šï¼šæ²¡æœ‰å¯ç”¨çš„RSSæº")
        return 1


if __name__ == "__main__":
    # è®¾ç½®äº‹ä»¶å¾ªç¯ç­–ç•¥ï¼ˆå…¼å®¹æ€§ï¼‰
    if sys.platform == "win32":
        asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())

    exit_code = asyncio.run(main())
    sys.exit(exit_code)
