#!/usr/bin/env python3
"""
é‡ç½®æ–‡ç« åˆ†æçŠ¶æ€
ç”¨äºé‡æ–°åˆ†æä¹‹å‰å¤±è´¥çš„æ–‡ç« 
"""

import os
import sys
from datetime import datetime, timedelta

sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from supabase import create_client


def reset_analysis_status(hours: int = 24, reset_all: bool = False):
    """
    é‡ç½®æ–‡ç« åˆ†æçŠ¶æ€

    Args:
        hours: é‡ç½®æœ€è¿‘å¤šå°‘å°æ—¶å†…çš„æ–‡ç« 
        reset_all: æ˜¯å¦é‡ç½®æ‰€æœ‰å·²åˆ†æçš„æ–‡ç« 
    """
    supabase_url = os.getenv("SUPABASE_URL")
    supabase_key = os.getenv("SUPABASE_KEY")

    if not supabase_url or not supabase_key:
        print("âŒ ç¼ºå°‘ Supabase é…ç½®")
        return

    supabase = create_client(supabase_url, supabase_key)

    if reset_all:
        # é‡ç½®æ‰€æœ‰å·²åˆ†æçš„æ–‡ç« 
        print("âš ï¸  é‡ç½®æ‰€æœ‰å·²åˆ†æçš„æ–‡ç« ...")
        result = (
            supabase.table("articles")
            .update({"analyzed_at": None})
            .neq("analyzed_at", "null")
            .execute()
        )
        print(f"âœ… å·²é‡ç½® {len(result.data)} ç¯‡æ–‡ç« ")

        # åˆ é™¤æ‰€æœ‰åˆ†æèšç±»
        print("âš ï¸  åˆ é™¤æ‰€æœ‰åˆ†æèšç±»...")
        supabase.table("analysis_clusters").delete().neq("id", 0).execute()
        print("âœ… å·²åˆ é™¤æ‰€æœ‰èšç±»")

        # åˆ é™¤æ‰€æœ‰ä¿¡å·
        print("âš ï¸  åˆ é™¤æ‰€æœ‰ä¿¡å·...")
        supabase.table("analysis_signals").delete().neq("id", 0).execute()
        print("âœ… å·²åˆ é™¤æ‰€æœ‰ä¿¡å·")

    else:
        # åªé‡ç½®æœ€è¿‘ N å°æ—¶çš„æ–‡ç« 
        cutoff_time = (datetime.now() - timedelta(hours=hours)).isoformat()

        print(f"ğŸ“ é‡ç½®æœ€è¿‘ {hours} å°æ—¶å†…åˆ†æçš„æ–‡ç« ...")

        # è·å–è¿™äº›æ–‡ç« 
        result = (
            supabase.table("articles")
            .select("id")
            .gte("analyzed_at", cutoff_time)
            .execute()
        )

        article_ids = [r["id"] for r in result.data]

        if not article_ids:
            print("âœ… æ²¡æœ‰æ‰¾åˆ°éœ€è¦é‡ç½®çš„æ–‡ç« ")
            return

        print(f"ğŸ“Š æ‰¾åˆ° {len(article_ids)} ç¯‡æ–‡ç« éœ€è¦é‡ç½®")

        # é‡ç½®æ–‡ç« çŠ¶æ€
        for article_id in article_ids:
            supabase.table("articles").update({"analyzed_at": None}).eq(
                "id", article_id
            ).execute()

        print(f"âœ… å·²é‡ç½® {len(article_ids)} ç¯‡æ–‡ç« çš„åˆ†æçŠ¶æ€")

        # åˆ é™¤ç›¸å…³çš„èšç±»
        print("ğŸ—‘ï¸  åˆ é™¤ç›¸å…³çš„èšç±»...")
        clusters = (
            supabase.table("analysis_clusters")
            .select("id")
            .gte("created_at", cutoff_time)
            .execute()
        )

        cluster_ids = [c["id"] for c in clusters.data]

        for cluster_id in cluster_ids:
            # åˆ é™¤å…³è”
            supabase.table("article_analyses").delete().eq(
                "cluster_id", cluster_id
            ).execute()
            # åˆ é™¤èšç±»
            supabase.table("analysis_clusters").delete().eq("id", cluster_id).execute()

        print(f"âœ… å·²åˆ é™¤ {len(cluster_ids)} ä¸ªèšç±»")


def reset_shallow_analysis():
    """
    åªé‡ç½®æµ…å±‚åˆ†æçš„æ–‡ç« ï¼ˆè®©çƒ­ç‚¹è¿›è¡Œæ·±åº¦åˆ†æï¼‰
    """
    supabase_url = os.getenv("SUPABASE_URL")
    supabase_key = os.getenv("SUPABASE_KEY")

    if not supabase_url or not supabase_key:
        print("âŒ ç¼ºå°‘ Supabase é…ç½®")
        return

    supabase = create_client(supabase_url, supabase_key)

    print("ğŸ“ æŸ¥æ‰¾æµ…å±‚åˆ†æçš„èšç±»...")

    # è·å–æµ…å±‚åˆ†æçš„èšç±»
    clusters = (
        supabase.table("analysis_clusters")
        .select("*")
        .eq("analysis_depth", "shallow")
        .execute()
    )

    if not clusters.data:
        print("âœ… æ²¡æœ‰æµ…å±‚åˆ†æçš„èšç±»")
        return

    print(f"ğŸ“Š æ‰¾åˆ° {len(clusters.data)} ä¸ªæµ…å±‚åˆ†æèšç±»")

    # è·å–å…³è”çš„æ–‡ç« ID
    cluster_ids = [c["id"] for c in clusters.data]

    relations = (
        supabase.table("article_analyses")
        .select("article_id")
        .in_("cluster_id", cluster_ids)
        .execute()
    )

    article_ids = list(set([r["article_id"] for r in relations.data]))

    print(f"ğŸ“Š æ¶‰åŠ {len(article_ids)} ç¯‡æ–‡ç« ")

    # é‡ç½®æ–‡ç« çŠ¶æ€
    for article_id in article_ids:
        supabase.table("articles").update({"analyzed_at": None}).eq(
            "id", article_id
        ).execute()

    print(f"âœ… å·²é‡ç½® {len(article_ids)} ç¯‡æ–‡ç« ")

    # åˆ é™¤æµ…å±‚èšç±»
    for cluster_id in cluster_ids:
        supabase.table("article_analyses").delete().eq(
            "cluster_id", cluster_id
        ).execute()
        supabase.table("analysis_clusters").delete().eq("id", cluster_id).execute()

    print(f"âœ… å·²åˆ é™¤ {len(cluster_ids)} ä¸ªæµ…å±‚èšç±»")


if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser(description="é‡ç½®æ–‡ç« åˆ†æçŠ¶æ€")
    parser.add_argument(
        "--hours", type=int, default=24, help="é‡ç½®æœ€è¿‘å¤šå°‘å°æ—¶å†…çš„æ–‡ç«  (é»˜è®¤: 24)"
    )
    parser.add_argument("--all", action="store_true", help="é‡ç½®æ‰€æœ‰å·²åˆ†æçš„æ–‡ç« ")
    parser.add_argument(
        "--shallow-only", action="store_true", help="åªé‡ç½®æµ…å±‚åˆ†æçš„æ–‡ç« "
    )

    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ”§ é‡ç½®æ–‡ç« åˆ†æçŠ¶æ€")
    print("=" * 60)

    if args.shallow_only:
        reset_shallow_analysis()
    else:
        reset_analysis_status(hours=args.hours, reset_all=args.all)

    print("=" * 60)
    print("âœ… é‡ç½®å®Œæˆï¼ç°åœ¨å¯ä»¥é‡æ–°è¿è¡Œ analyzer.py äº†")
    print("=" * 60)
