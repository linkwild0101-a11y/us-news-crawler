name: RSS Crawler

on:
  schedule:
    # 东部时间 9:00 AM (UTC 14:00) - 冬季
    # 夏令时期间会变成东部 10:00 AM
    - cron: '0 14 * * *'
    # 东部时间 9:00 PM (UTC 02:00，次日) - 冬季
    # 夏令时期间会变成东部 10:00 PM
    - cron: '0 2 * * *'
  workflow_dispatch:

jobs:
  crawl:
    runs-on: ubuntu-latest
    timeout-minutes: 360
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
    
    - name: Run crawler
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        WORKER_URL: ${{ secrets.WORKER_URL }}
      run: |
        python scripts/crawler.py
    
    - name: Cleanup old data
      env:
        SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
        SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
      run: |
        python scripts/cleanup.py
